{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import argparse\n",
    "import json\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from search import search, search_fast\n",
    "from utils import to_gpu, Corpus, batchify, SNLIDataset, train_ngram_lm, get_ppl, load_ngram_lm, get_delta, collate_snli\n",
    "from models import Seq2Seq, MLP_D, MLP_G, MLP_I, MLP_I_AE, JSDistance, Seq2SeqCAE, Baseline_Embeddings, Baseline_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1.post2\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Generating Natural Adversaries for Text')\n",
    "\n",
    "# Path Arguments\n",
    "parser.add_argument('--data_path', type=str, default='./data',\n",
    "                    help='path to data corpus ./data')\n",
    "parser.add_argument('--classifier_path', type=str, default='./models',\n",
    "                    help='path to classifier files ./models')\n",
    "parser.add_argument('--kenlm_path', type=str, default='./models/kenlm',\n",
    "                    help='path to kenlm directory')\n",
    "parser.add_argument('--outf', type=str, default='',\n",
    "                    help='output directory name')\n",
    "\n",
    "# Data Processing Arguments\n",
    "parser.add_argument('--vocab_size', type=int, default=11000,\n",
    "                    help='cut vocabulary down to this size (most frequently seen in training)')\n",
    "parser.add_argument('--maxlen', type=int, default=10,\n",
    "                    help='maximum sentence length')\n",
    "parser.add_argument('--lowercase', type=bool, default=True,\n",
    "                    help='lowercase all text')\n",
    "parser.add_argument('--packed_rep', type=bool, default=False,\n",
    "                    help='pad all sentences to fixed maxlen')\n",
    "\n",
    "# Model Arguments\n",
    "parser.add_argument('--emsize', type=int, default=300,\n",
    "                    help='size of word embeddings')\n",
    "parser.add_argument('--nhidden', type=int, default=300,\n",
    "                    help='number of hidden units per layer in LSTM')\n",
    "parser.add_argument('--nlayers', type=int, default=1,\n",
    "                    help='number of layers')\n",
    "parser.add_argument('--noise_radius', type=float, default=0.2,\n",
    "                    help='stdev of noise for autoencoder (regularizer)')\n",
    "parser.add_argument('--noise_anneal', type=float, default=0.995,\n",
    "                    help='anneal noise_radius exponentially by this every 100 iterations')\n",
    "parser.add_argument('--hidden_init', action='store_true',\n",
    "                    help=\"initialize decoder hidden state with encoder's\")\n",
    "parser.add_argument('--arch_i', type=str, default='300-300',\n",
    "                    help='inverter architecture (MLP)')\n",
    "parser.add_argument('--arch_g', type=str, default='300-300',\n",
    "                    help='generator architecture (MLP)')\n",
    "parser.add_argument('--arch_d', type=str, default='300-300',\n",
    "                    help='critic/discriminator architecture (MLP)')\n",
    "parser.add_argument('--arch_conv_filters', type=str, default='500-700-1000',\n",
    "                    help='encoder filter sizes for different convolutional layers')\n",
    "parser.add_argument('--arch_conv_strides', type=str, default='1-2-2',\n",
    "                    help='encoder strides for different convolutional layers')\n",
    "parser.add_argument('--arch_conv_windows', type=str, default='3-3-3',\n",
    "                    help='encoder window sizes for different convolutional layers')\n",
    "parser.add_argument('--z_size', type=int, default=100,\n",
    "                    help='dimension of random noise z to feed into generator')\n",
    "parser.add_argument('--temp', type=float, default=1,\n",
    "                    help='softmax temperature (lower --> more discrete)')\n",
    "parser.add_argument('--enc_grad_norm', type=bool, default=True,\n",
    "                    help='norm code gradient from critic->encoder')\n",
    "parser.add_argument('--gan_toenc', type=float, default=-0.01,\n",
    "                    help='weight factor passing gradient from gan to encoder')\n",
    "parser.add_argument('--dropout', type=float, default=0.0,\n",
    "                    help='dropout applied to layers (0 = no dropout)')\n",
    "parser.add_argument('--useJS', type=bool, default=True,\n",
    "                    help='use Jenson Shannon distance')\n",
    "parser.add_argument('--perturb_z', type=bool, default=True,\n",
    "                    help='perturb noise space z instead of hidden c')\n",
    "\n",
    "# Training Arguments\n",
    "parser.add_argument('--epochs', type=int, default=15,\n",
    "                    help='maximum number of epochs')\n",
    "parser.add_argument('--min_epochs', type=int, default=20,\n",
    "                    help=\"minimum number of epochs to train for\")\n",
    "parser.add_argument('--no_earlystopping', action='store_true',\n",
    "                    help=\"won't use KenLM for early stopping\")\n",
    "parser.add_argument('--patience', type=int, default=5,\n",
    "                    help=\"language model evaluations w/o ppl improvement before early stopping\")\n",
    "parser.add_argument('--batch_size', type=int, default=1, metavar='N',\n",
    "                    help='batch size')\n",
    "parser.add_argument('--niters_ae', type=int, default=1,\n",
    "                    help='number of autoencoder iterations in training')\n",
    "parser.add_argument('--niters_gan_d', type=int, default=5,\n",
    "                    help='number of discriminator iterations in training')\n",
    "parser.add_argument('--niters_gan_g', type=int, default=1,\n",
    "                    help='number of generator iterations in training')\n",
    "parser.add_argument('--niters_inv', type=int, default=5,\n",
    "                    help='number of inverter iterations in training')\n",
    "parser.add_argument('--niters_gan_schedule', type=str, default='2-4-6',\n",
    "                    help='epochs to increase GAN training iterations (increase by 1 each time)')\n",
    "parser.add_argument('--lr_ae', type=float, default=1,\n",
    "                    help='autoencoder learning rate')\n",
    "parser.add_argument('--lr_inv', type=float, default=1e-05,\n",
    "                    help='inverter learning rate')\n",
    "parser.add_argument('--lr_gan_g', type=float, default=5e-05,\n",
    "                    help='generator learning rate')\n",
    "parser.add_argument('--lr_gan_d', type=float, default=1e-05,\n",
    "                    help='critic/discriminator learning rate')\n",
    "parser.add_argument('--beta1', type=float, default=0.9,\n",
    "                    help='beta1 for adam. default=0.9')\n",
    "parser.add_argument('--clip', type=float, default=1,\n",
    "                    help='gradient clipping, max norm')\n",
    "parser.add_argument('--gan_clamp', type=float, default=0.01,\n",
    "                    help='WGAN clamp')\n",
    "parser.add_argument('--convolution_enc', action='store_true', default=True,\n",
    "                    help='use convolutions in encoder')\n",
    "parser.add_argument('--use_inv_ae', action='store_true', default=False,\n",
    "                    help='use encoder->inv->gen->dec')\n",
    "parser.add_argument('--update_base', action='store_true', default=True,\n",
    "                    help='updating base models')\n",
    "parser.add_argument('--load_pretrained', type=str, default=None,\n",
    "                    help='load a pre-trained encoder and decoder to train the inverter')\n",
    "parser.add_argument('--reload_exp', type=str, default=None,\n",
    "                    help='resume a previous experiment')\n",
    "\n",
    "# Evaluation Arguments\n",
    "parser.add_argument('--sample', action='store_true',\n",
    "                    help='sample when decoding for generation')\n",
    "parser.add_argument('--N', type=int, default=5,\n",
    "                    help='N-gram order for training n-gram language model')\n",
    "parser.add_argument('--log_interval', type=int, default=200,\n",
    "                    help='interval to log autoencoder training results')\n",
    "\n",
    "# Other\n",
    "parser.add_argument('--seed', type=int, default=1111,\n",
    "                    help='random seed')\n",
    "parser.add_argument('--cuda', action='store_true', default=True,\n",
    "                    help='use CUDA')\n",
    "parser.add_argument('--debug_mode', action='store_true', default=False,\n",
    "                    help='debug mode to not create a new dir')\n",
    "parser.add_argument('--hybrid', type=bool, default=False,\n",
    "                    help='performs hybrid search')\n",
    "\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device gpu:0\n"
     ]
    }
   ],
   "source": [
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.device(0)\n",
    "    print(\"using cuda device gpu:\" + format(torch.cuda.current_device()))\n",
    "    torch.cuda.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.debug_mode:\n",
    "    args.outf = \"debug\"\n",
    "elif args.reload_exp:\n",
    "    args.outf = args.reload_exp\n",
    "else:\n",
    "    args.outf = str(int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.load_pretrained = '1556583694'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving into directory ./output/1556975304\n",
      "Loading pretrained models from ./output/1556583694\n"
     ]
    }
   ],
   "source": [
    "# make output directory if it doesn't already exist\n",
    "if not os.path.isdir('./output'):\n",
    "    os.makedirs('./output')\n",
    "if not os.path.isdir('./output/{}'.format(args.outf)):\n",
    "    os.makedirs('./output/{}'.format(args.outf))\n",
    "    os.makedirs('./output/{}'.format(args.outf + \"/models\"))\n",
    "print(\"Saving into directory ./output/{0}\".format(args.outf))\n",
    "\n",
    "if args.reload_exp:\n",
    "    cur_dir = './output/{}'.format(args.reload_exp)\n",
    "    print(\"Loading previous experiment from \" + cur_dir)\n",
    "elif args.load_pretrained:\n",
    "    cur_dir = './output/{}'.format(args.load_pretrained)\n",
    "    print(\"Loading pretrained models from \" + cur_dir)\n",
    "else:\n",
    "    cur_dir = './output/{}'.format(args.outf)\n",
    "    print(\"Creating new experiment at \" + cur_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading vocabulary from ./output/1556583694/vocab.json\n",
      "\n",
      "Number of sentences dropped from ./data/train.txt: 270949 out of 714667 total\n",
      "Number of sentences dropped from ./data/test.txt: 5481 out of 13323 total\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Load data and target classifiers\n",
    "###############################################################################\n",
    "\n",
    "# create corpus\n",
    "if args.reload_exp or args.load_pretrained:\n",
    "    corpus = Corpus(args.data_path,\n",
    "                    maxlen=args.maxlen,\n",
    "                    vocab_size=args.vocab_size,\n",
    "                    lowercase=args.lowercase,\n",
    "                    load_vocab=cur_dir + '/vocab.json')\n",
    "else:\n",
    "    corpus = Corpus(args.data_path,\n",
    "                    maxlen=args.maxlen,\n",
    "                    vocab_size=args.vocab_size,\n",
    "                    lowercase=args.lowercase)\n",
    "\n",
    "if not args.convolution_enc:\n",
    "    args.packed_rep = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences dropped from ./data/classifier/test.txt: 8288 out of 9824 total\n",
      "LSTM(100, 300, batch_first=True)\n",
      "Loaded data and target classifiers!\n"
     ]
    }
   ],
   "source": [
    "train_data = batchify(corpus.train, args.batch_size, args.maxlen,\n",
    "                      packed_rep=args.packed_rep, shuffle=True)\n",
    "valid_data = batchify(corpus.test, args.batch_size, args.maxlen,\n",
    "                      packed_rep=args.packed_rep, shuffle=False)\n",
    "\n",
    "corpus_test = SNLIDataset(train=False, vocab_size=args.vocab_size+4,\n",
    "                          reset_vocab=corpus.dictionary.word2idx)\n",
    "testloader = torch.utils.data.DataLoader(corpus_test, batch_size=10,\n",
    "                                         collate_fn=collate_snli, shuffle=False)\n",
    "test_data = iter(testloader)        # different format from train_data and valid_data\n",
    "\n",
    "classifier1 = Baseline_Embeddings(100, vocab_size=args.vocab_size+4)\n",
    "classifier1.load_state_dict(torch.load(args.classifier_path + \"/baseline/model_emb.pt\"))\n",
    "vocab_classifier1 = pkl.load(open(args.classifier_path + \"/vocab.pkl\", 'rb'))\n",
    "\n",
    "classifier2 = Baseline_LSTM(100, 300, maxlen=10, gpu=args.cuda)\n",
    "classifier2.load_state_dict(torch.load(args.classifier_path + \"/baseline/model_lstm.pt\"))\n",
    "vocab_classifier2 = pkl.load(open(args.classifier_path + \"/vocab.pkl\", 'rb'))\n",
    "\n",
    "print(\"Loaded data and target classifiers!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./output/1556583694'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 11004\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Build the models\n",
    "###############################################################################\n",
    "ntokens = len(corpus.dictionary.word2idx)\n",
    "args.ntokens = ntokens\n",
    "print(\"Vocabulary Size: {}\".format(ntokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverter = torch.load(open('output/1556583694/' + '/models/inverter_model.pt','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/guojy/anaconda3/envs/pt1/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'models.Seq2SeqCAE' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "if args.reload_exp or args.load_pretrained:\n",
    "    autoencoder = torch.load(open(cur_dir + '/models/autoencoder_model.pt', 'rb'))\n",
    "    gan_gen = torch.load(open(cur_dir + '/models/gan_gen_model.pt', 'rb'))\n",
    "    gan_disc = torch.load(open(cur_dir + '/models/gan_disc_model.pt', 'rb'))\n",
    "    with open(cur_dir + '/vocab.json', 'r') as f:\n",
    "        corpus.dictionary.word2idx = json.load(f)\n",
    "\n",
    "    if args.load_pretrained:\n",
    "        inverter = MLP_I(args.nhidden, args.z_size, args.arch_i, gpu=args.cuda)\n",
    "    else:\n",
    "        inverter = torch.load(open(cur_dir + '/models/inverter_model.pt','rb'))\n",
    "else:\n",
    "    if args.convolution_enc:\n",
    "        autoencoder = Seq2SeqCAE(emsize=args.emsize,\n",
    "                                 nhidden=args.nhidden,\n",
    "                                 ntokens=ntokens,\n",
    "                                 nlayers=args.nlayers,\n",
    "                                 noise_radius=args.noise_radius,\n",
    "                                 hidden_init=args.hidden_init,\n",
    "                                 dropout=args.dropout,\n",
    "                                 conv_layer=args.arch_conv_filters,\n",
    "                                 conv_windows=args.arch_conv_windows,\n",
    "                                 conv_strides=args.arch_conv_strides,\n",
    "                                 gpu=args.cuda)\n",
    "    else:\n",
    "        autoencoder = Seq2Seq(emsize=args.emsize,\n",
    "                              nhidden=args.nhidden,\n",
    "                              ntokens=ntokens,\n",
    "                              nlayers=args.nlayers,\n",
    "                              noise_radius=args.noise_radius,\n",
    "                              hidden_init=args.hidden_init,\n",
    "                              dropout=args.dropout,\n",
    "                              gpu=args.cuda)\n",
    "    inverter = MLP_I_AE(ninput=args.nhidden, noutput=args.z_size, layers=args.arch_i)\n",
    "    gan_gen = MLP_G(ninput=args.z_size, noutput=args.nhidden, layers=args.arch_g)\n",
    "    gan_disc = MLP_D(ninput=args.nhidden, noutput=1, layers=args.arch_d)\n",
    "    # dumping vocabulary\n",
    "    with open('./output/{}/vocab.json'.format(args.outf), 'w') as f:\n",
    "        # json.dump(corpus.dictionary.word2idx, f, encoding='utf-8')\n",
    "        json.dump(corpus.dictionary.word2idx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2SeqCAE(\n",
      "  (embedding): Embedding(11004, 300)\n",
      "  (embedding_decoder): Embedding(11004, 300)\n",
      "  (encoder): Sequential(\n",
      "    (layer-1): Conv1d(300, 500, kernel_size=(3,), stride=(1,))\n",
      "    (bn-1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation-1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (layer-2): Conv1d(500, 700, kernel_size=(3,), stride=(2,))\n",
      "    (bn-2): BatchNorm1d(700, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation-2): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (layer-3): Conv1d(700, 1000, kernel_size=(3,), stride=(2,))\n",
      "    (bn-3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation-3): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (linear): Linear(in_features=1000, out_features=300, bias=True)\n",
      "  (decoder): LSTM(600, 300, batch_first=True)\n",
      "  (linear_dec): Linear(in_features=300, out_features=11004, bias=True)\n",
      ")\n",
      "MLP_I(\n",
      "  (layer1): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (bn1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation1): ReLU()\n",
      "  (layer2): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation2): ReLU()\n",
      "  (layer7): Linear(in_features=300, out_features=100, bias=True)\n",
      ")\n",
      "MLP_G(\n",
      "  (layer1): Linear(in_features=100, out_features=300, bias=True)\n",
      "  (bn1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation1): ReLU()\n",
      "  (layer2): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation2): ReLU()\n",
      "  (layer7): Linear(in_features=300, out_features=300, bias=True)\n",
      ")\n",
      "MLP_D(\n",
      "  (layer1): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (activation1): LeakyReLU(negative_slope=0.2)\n",
      "  (layer2): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation2): LeakyReLU(negative_slope=0.2)\n",
      "  (layer6): Linear(in_features=300, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(autoencoder)\n",
    "print(inverter)\n",
    "print(gan_gen)\n",
    "print(gan_disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_ae = optim.SGD(autoencoder.parameters(),\n",
    "                         lr=args.lr_ae)\n",
    "optimizer_inv = optim.Adam(inverter.parameters(),\n",
    "                           lr=args.lr_inv, betas=(args.beta1, 0.999))\n",
    "optimizer_gan_g = optim.Adam(gan_gen.parameters(),\n",
    "                             lr=args.lr_gan_g, betas=(args.beta1, 0.999))\n",
    "optimizer_gan_d = optim.Adam(gan_disc.parameters(),\n",
    "                             lr=args.lr_gan_d, betas=(args.beta1, 0.999))\n",
    "\n",
    "criterion_ce = nn.CrossEntropyLoss()\n",
    "criterion_mse = nn.MSELoss()\n",
    "criterion_js = JSDistance()\n",
    "\n",
    "if args.cuda:\n",
    "    autoencoder = autoencoder.cuda()\n",
    "    inverter = inverter.cuda()\n",
    "    gan_gen = gan_gen.cuda()\n",
    "    gan_disc = gan_disc.cuda()\n",
    "    criterion_ce = criterion_ce.cuda()\n",
    "    classifier1 = classifier1.cuda()\n",
    "    classifier2 = classifier2.cuda()\n",
    "else:\n",
    "    autoencoder.gpu = False\n",
    "    autoencoder = autoencoder.cpu()\n",
    "    inverter = inverter.cpu()\n",
    "    gan_gen = gan_gen.cpu()\n",
    "    gan_disc = gan_disc.cpu()\n",
    "    classifier1.cpu()\n",
    "    classifier2.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schedule of increasing GAN training loops\n",
    "if args.niters_gan_schedule != \"\":\n",
    "    gan_schedule = [int(x) for x in args.niters_gan_schedule.split(\"-\")]\n",
    "else:\n",
    "    gan_schedule = []\n",
    "niter_gan = 1\n",
    "\n",
    "fixed_noise = to_gpu(args.cuda, Variable(torch.ones(args.batch_size, args.z_size)))\n",
    "fixed_noise.data.normal_(0, 1)\n",
    "one = to_gpu(args.cuda, torch.FloatTensor([1]))\n",
    "mone = one * -1\n",
    "\n",
    "impatience = 0\n",
    "all_ppl = []\n",
    "best_ppl = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_ae = 0\n",
    "epoch_start_time = time.time()\n",
    "start_time = time.time()\n",
    "niter = 0\n",
    "niter_global = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ae(batch, total_loss_ae, start_time, i,\n",
    "             args, autoencoder, optimizer_ae, criterion_ce, n_train_data, epoch):\n",
    "    autoencoder.train()\n",
    "    autoencoder.zero_grad()\n",
    "\n",
    "    source, target, lengths = batch\n",
    "    source = to_gpu(args.cuda, Variable(source))\n",
    "    target = to_gpu(args.cuda, Variable(target))\n",
    "\n",
    "    # Create sentence length mask over padding\n",
    "    mask = target.gt(0)\n",
    "    masked_target = target.masked_select(mask)\n",
    "    # examples x ntokens\n",
    "    output_mask = mask.unsqueeze(1).expand(mask.size(0), ntokens)\n",
    "\n",
    "    # output: batch x seq_len x ntokens\n",
    "    output = autoencoder(source, lengths, noise=True)\n",
    "\n",
    "    # output_size: batch_size, maxlen, self.ntokens\n",
    "    flattened_output = output.view(-1, ntokens)\n",
    "\n",
    "    masked_output = flattened_output.masked_select(output_mask).view(-1, ntokens)\n",
    "    loss = criterion_ce(masked_output/args.temp, masked_target)\n",
    "    loss.backward()\n",
    "\n",
    "    # `clip_grad_norm` to prevent exploding gradient in RNNs / LSTMs\n",
    "    torch.nn.utils.clip_grad_norm(autoencoder.parameters(), args.clip)\n",
    "    optimizer_ae.step()\n",
    "\n",
    "    total_loss_ae += loss.data\n",
    "\n",
    "    accuracy = None\n",
    "    if i % args.log_interval == 0 and i > 0:\n",
    "        # accuracy\n",
    "        probs = F.softmax(masked_output)\n",
    "        max_vals, max_indices = torch.max(probs, 1)\n",
    "        # accuracy = torch.mean(max_indices.eq(masked_target).float()).data[0]\n",
    "        accuracy = torch.mean(max_indices.eq(masked_target).float()).data.item()\n",
    "\n",
    "        # cur_loss = total_loss_ae[0] / args.log_interval\n",
    "        cur_loss = total_loss_ae.item() / args.log_interval\n",
    "        elapsed = time.time() - start_time\n",
    "        print('| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | '\n",
    "              'loss {:5.2f} | ppl {:8.2f} | acc {:8.2f}'\n",
    "              .format(epoch, i, n_train_data,\n",
    "                      elapsed * 1000 / args.log_interval,\n",
    "                      cur_loss, math.exp(cur_loss), accuracy))\n",
    "\n",
    "        with open(\"./output/{}/logs.txt\".format(args.outf), 'a') as f:\n",
    "            f.write('| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | '\n",
    "                    'loss {:5.2f} | ppl {:8.2f} | acc {:8.2f}\\n'.\n",
    "                    format(epoch, i, n_train_data,\n",
    "                           elapsed * 1000 / args.log_interval,\n",
    "                           cur_loss, math.exp(cur_loss), accuracy))\n",
    "\n",
    "        total_loss_ae = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "    return total_loss_ae, start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ae(train_data[niter], total_loss_ae, start_time, niter,\n",
    "                             args, autoencoder, optimizer_ae, criterion_ce,\n",
    "                             len(train_data), epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = train_data[0]\n",
    "autoencoder.eval()\n",
    "\n",
    "source, target, lengths = batch\n",
    "source = to_gpu(args.cuda, Variable(source))\n",
    "target = to_gpu(args.cuda, Variable(target))\n",
    "\n",
    "# Create sentence length mask over padding\n",
    "mask = target.gt(0)\n",
    "masked_target = target.masked_select(mask)\n",
    "# examples x ntokens\n",
    "output_mask = mask.unsqueeze(1).expand(mask.size(0), ntokens)\n",
    "\n",
    "output = autoencoder(source, lengths, noise=True)\n",
    "\n",
    "# output_size: batch_size, maxlen, self.ntokens\n",
    "flattened_output = output.view(-1, ntokens)\n",
    "\n",
    "masked_output = flattened_output.masked_select(output_mask).view(-1, ntokens)\n",
    "\n",
    "#loss = criterion_ce(masked_output/args.temp, masked_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 11004])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1716, -0.3986, -3.7944,  ..., -0.7063, -0.8574,  0.8694],\n",
       "       device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9754,  5586,  4885, 10527,  3733,  8851,    22,     2],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/guojy/anaconda3/envs/pt1/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "probs = F.softmax(masked_output)\n",
    "max_vals, max_indices = torch.max(probs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 11004])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 0.9999, 0.9989, 1.0000, 1.0000, 0.9986],\n",
       "       device='cuda:0', grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the man is waiting for someone . <eos>\n"
     ]
    }
   ],
   "source": [
    "#直接用autoencoder enc -> dec 得到的句子， 中间的hidden是noise=True (用了hidden+noise)\n",
    "#对应的概率矩阵是probs, 对应的max概率是max_vals\n",
    "max_indices\n",
    "print(' '.join([corpus.dictionary.idx2word[w.item()] for w in max_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the man is waiting for someone . <eos>\n"
     ]
    }
   ],
   "source": [
    "#原句\n",
    "print(' '.join([corpus.dictionary.idx2word[w.item()] for w in masked_target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, indices, lengths, noise, encode_only=False, generator=None, inverter=None):\n",
    "    if not generator:   # only enc -> dec\n",
    "        batch_size, maxlen = indices.size()\n",
    "        self.embedding.weight.data[0].fill_(0)\n",
    "        self.embedding_decoder.weight.data[0].fill_(0)\n",
    "        hidden = self.encode(indices, lengths, noise)\n",
    "        if encode_only:\n",
    "            return hidden\n",
    "\n",
    "        if hidden.requires_grad:\n",
    "            hidden.register_hook(self.store_grad_norm)\n",
    "\n",
    "        decoded = self.decode(hidden, batch_size, maxlen,\n",
    "                          indices=indices, lengths=lengths)\n",
    "    else:               # enc -> inv -> gen -> dec\n",
    "        batch_size, maxlen = indices.size()\n",
    "        self.embedding.weight.data[0].fill_(0)\n",
    "        self.embedding_decoder.weight.data[0].fill_(0)\n",
    "        hidden = self.encode(indices, lengths, noise)\n",
    "        if encode_only:\n",
    "            return hidden\n",
    "\n",
    "        if hidden.requires_grad:\n",
    "            hidden.register_hook(self.store_grad_norm)\n",
    "\n",
    "        z_hat = inverter(hidden)\n",
    "        c_hat = generator(z_hat)\n",
    "\n",
    "        decoded = self.decode(c_hat, batch_size, maxlen,\n",
    "                          indices=indices, lengths=lengths)\n",
    "\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(self, indices, lengths, noise):\n",
    "    embeddings = self.embedding(indices)\n",
    "    embeddings = embeddings.transpose(1,2)\n",
    "    c_pre_lin = self.encoder(embeddings)\n",
    "    c_pre_lin = c_pre_lin.squeeze(2)\n",
    "    hidden = self.linear(c_pre_lin)\n",
    "    # normalize to unit ball (l2 norm of 1) - p=2, dim=1\n",
    "    norms = torch.norm(hidden, 2, 1)\n",
    "    if norms.ndimension()==1:\n",
    "        norms=norms.unsqueeze(1)\n",
    "    hidden = torch.div(hidden, norms.expand_as(hidden))\n",
    "\n",
    "    if noise and self.noise_radius > 0:\n",
    "        gauss_noise = torch.normal(mean=torch.zeros(hidden.size()),\n",
    "                                   std=self.noise_radius)\n",
    "        if self.gpu:\n",
    "            gauss_noise = gauss_noise.cuda()\n",
    "\n",
    "        hidden = hidden + to_gpu(self.gpu, Variable(gauss_noise))\n",
    "\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(self, hidden, maxlen, sample=True, temp=1.0):\n",
    "    \"\"\"Generate through decoder; no backprop\"\"\"\n",
    "    if hidden.ndimension() == 1:\n",
    "        hidden = hidden.unsqueeze(0)\n",
    "    batch_size = hidden.size(0)\n",
    "\n",
    "    if self.hidden_init:\n",
    "        # initialize decoder hidden state to encoder output\n",
    "        state = (hidden.unsqueeze(0), self.init_state(batch_size))\n",
    "    else:\n",
    "        state = self.init_hidden(batch_size)\n",
    "\n",
    "    if not self.gpu:\n",
    "        self.start_symbols = self.start_symbols.cpu()\n",
    "    else:\n",
    "        self.start_symbols = self.start_symbols.cuda()\n",
    "    # <sos>\n",
    "    self.start_symbols.data.resize_(batch_size, 1)\n",
    "    self.start_symbols.data.fill_(1)\n",
    "\n",
    "    embedding = self.embedding_decoder(self.start_symbols)\n",
    "    inputs = torch.cat([embedding, hidden.unsqueeze(1)], 2)\n",
    "\n",
    "    # unroll\n",
    "    all_indices = []\n",
    "    for i in range(maxlen):\n",
    "        output, state = self.decoder(inputs, state)\n",
    "        overvocab = self.linear_dec(output.squeeze(1))\n",
    "\n",
    "        if not sample:\n",
    "            vals, indices = torch.max(overvocab, 1)\n",
    "        else:\n",
    "            # sampling\n",
    "            probs = F.softmax(overvocab/temp)\n",
    "            indices = torch.multinomial(probs, 1)\n",
    "\n",
    "        if indices.ndimension()==1:\n",
    "            indices = indices.unsqueeze(1)\n",
    "        all_indices.append(indices)\n",
    "\n",
    "        embedding = self.embedding_decoder(indices)\n",
    "        inputs = torch.cat([embedding, hidden.unsqueeze(1)], 2)\n",
    "\n",
    "    max_indices = torch.cat(all_indices, 1)\n",
    "\n",
    "    return max_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = source\n",
    "encode_only=False\n",
    "generator=None\n",
    "inverter=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = autoencoder\n",
    "# enc -> dec\n",
    "batch_size, maxlen = indices.size()\n",
    "self.embedding.weight.data[0].fill_(0)\n",
    "self.embedding_decoder.weight.data[0].fill_(0)\n",
    "hidden_withnoise = self.encode(indices, lengths, noise=True)\n",
    "hidden_nonoise = self.encode(indices,lengths,noise=False)\n",
    "\n",
    "if hidden_withnoise.requires_grad:\n",
    "    hidden_withnoise.register_hook(self.store_grad_norm)\n",
    "if hidden_nonoise.requires_grad:\n",
    "    hidden_nonoise.register_hook(self.store_grad_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 300])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_withnoise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 11004])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/guojy/natural-adversary/textSNLI/models.py:318: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(overvocab/temp)\n"
     ]
    }
   ],
   "source": [
    "#enc-> generate\n",
    "max_indices_generated_withnoise_temp1 = autoencoder.generate(hidden_withnoise, args.maxlen, sample=True, temp=1.0)\n",
    "max_indices_generated_withnoise_temp15 = autoencoder.generate(hidden_withnoise, args.maxlen, sample=True, temp=1.5)\n",
    "max_indices_generated_withnoise_temp05 = autoencoder.generate(hidden_withnoise, args.maxlen, sample=True, temp=0.5)\n",
    "max_indices_generated_nonoise_temp1 = autoencoder.generate(hidden_nonoise, args.maxlen, sample=True, temp=1.0)\n",
    "max_indices_generated_nonoise_temp15 = autoencoder.generate(hidden_nonoise, args.maxlen, sample=True, temp=1.5)\n",
    "max_indices_generated_nonoise_temp05 = autoencoder.generate(hidden_nonoise, args.maxlen, sample=True, temp=0.5)\n",
    "max_indices_generated_withnoise = autoencoder.generate(hidden_withnoise, args.maxlen, sample=False, temp=1)\n",
    "max_indices_generated_nonoise = autoencoder.generate(hidden_nonoise, args.maxlen, sample=False, temp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverter = torch.load(open('output/1556583694/' + '/models/inverter_model.pt','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enc->inv->gen->dec\n",
    "inverter.eval()\n",
    "gan_gen.eval()\n",
    "inv_noise_withnoise = inverter(hidden_withnoise)\n",
    "inv_noise_nonoise = inverter(hidden_nonoise)\n",
    "inv_hidden_withnoise = gan_gen(inv_noise_withnoise)\n",
    "inv_hidden_nonoise = gan_gen(inv_noise_nonoise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inv hidden\n",
    "autoencoder.eval()\n",
    "max_indices_invhidden_generated_withnoise_temp1 = autoencoder.generate(inv_hidden_withnoise, args.maxlen, sample=True, temp=1.0)\n",
    "max_indices_invhidden_generated_withnoise_temp15 = autoencoder.generate(inv_hidden_withnoise, args.maxlen, sample=True, temp=1.5)\n",
    "max_indices_invhidden_generated_withnoise_temp05 = autoencoder.generate(inv_hidden_withnoise, args.maxlen, sample=True, temp=0.5)\n",
    "max_indices_invhidden_generated_nonoise_temp1 = autoencoder.generate(inv_hidden_nonoise, args.maxlen, sample=True, temp=1.0)\n",
    "max_indices_invhidden_generated_nonoise_temp15 = autoencoder.generate(inv_hidden_nonoise, args.maxlen, sample=True, temp=1.5)\n",
    "max_indices_invhidden_generated_nonoise_temp05 = autoencoder.generate(inv_hidden_nonoise, args.maxlen, sample=True, temp=0.5)\n",
    "max_indices_invhidden_generated_withnoise = autoencoder.generate(inv_hidden_withnoise, args.maxlen, sample=False, temp=1)\n",
    "max_indices_invhidden_generated_nonoise = autoencoder.generate(inv_hidden_nonoise, args.maxlen, sample=False, temp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> the man is waiting for someone . <pad> <pad>'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#原始的句子\n",
    "' '.join([corpus.dictionary.idx2word[x.item()] for x in indices[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the man is waiting for someone . <eos>\n"
     ]
    }
   ],
   "source": [
    "#enc->dec\n",
    "#直接用autoencoder加原句得到的句子(取argmax)， 中间的hidden是noise=True (用了hidden+noise)\n",
    "#对应的概率矩阵是probs, 对应的max概率是max_vals\n",
    "print(' '.join([corpus.dictionary.idx2word[w.item()] for w in max_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the man is waiting for someone . <eos> <eos> man\n",
      "the man is waiting wore peoples . <eos> <eos> the\n",
      "the man is waiting for someone . <eos> <eos> man\n",
      "the man is waiting for someone . <eos> <eos> <eos>\n",
      "the man is waiting for someone . <eos> <eos> <eos>\n",
      "the man is waiting for someone . <eos> <eos> man\n",
      "the man is waiting for someone . <eos> <eos> man\n",
      "the man is waiting for someone . <eos> <eos> man\n"
     ]
    }
   ],
   "source": [
    "# enc->gen\n",
    "#用hidden generate出的句子\n",
    "print(' '.join([corpus.dictionary.idx2word[x.item()] for x in max_indices_generated_withnoise_temp1[0]]))\n",
    "print(' '.join([corpus.dictionary.idx2word[x.item()] for x in max_indices_generated_withnoise_temp15[0]]))\n",
    "print(' '.join([corpus.dictionary.idx2word[x.item()] for x in max_indices_generated_withnoise_temp05[0]]))\n",
    "print(' '.join([corpus.dictionary.idx2word[x.item()] for x in max_indices_generated_nonoise_temp1[0]]))\n",
    "print(' '.join([corpus.dictionary.idx2word[x.item()] for x in max_indices_generated_nonoise_temp15[0]]))\n",
    "print(' '.join([corpus.dictionary.idx2word[x.item()] for x in max_indices_generated_nonoise_temp05[0]]))\n",
    "print(' '.join([corpus.dictionary.idx2word[x.item()] for x in max_indices_generated_withnoise[0]]))\n",
    "print(' '.join([corpus.dictionary.idx2word[x.item()] for x in max_indices_generated_nonoise[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very large large moving street moving about new moving new\n",
      "large orange moving serving new outdoor moving about new very\n",
      "orange orange moving new moving about moving moving about moving\n",
      "large moving street moving about about moving large moving outdoor\n",
      "drumstick large orange red new moving moving out moving orange\n",
      "very large moving street moving about moving about moving moving\n",
      "very large moving street moving about moving about moving moving\n",
      "very large moving street moving about moving about moving moving\n"
     ]
    }
   ],
   "source": [
    "#enc->inv->gan_gen->gen\n",
    "#用inv generate出的句子\n",
    "print(' '.join([corpus.dictionary.idx2word[x.item()] for x in max_indices_invhidden_generated_withnoise_temp1[0]]))\n",
    "print(' '.join([corpus.dictionary.idx2word[x.item()] for x in max_indices_invhidden_generated_withnoise_temp15[0]]))\n",
    "print(' '.join([corpus.dictionary.idx2word[x.item()] for x in max_indices_invhidden_generated_withnoise_temp05[0]]))\n",
    "print(' '.join([corpus.dictionary.idx2word[x.item()] for x in max_indices_invhidden_generated_nonoise_temp1[0]]))\n",
    "print(' '.join([corpus.dictionary.idx2word[x.item()] for x in max_indices_invhidden_generated_nonoise_temp15[0]]))\n",
    "print(' '.join([corpus.dictionary.idx2word[x.item()] for x in max_indices_invhidden_generated_nonoise_temp05[0]]))\n",
    "print(' '.join([corpus.dictionary.idx2word[x.item()] for x in max_indices_invhidden_generated_withnoise[0]]))\n",
    "print(' '.join([corpus.dictionary.idx2word[x.item()] for x in max_indices_invhidden_generated_nonoise[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perturb(data_source, epoch, corpus_test, hybrid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utils.SNLIDataset at 0x7ff696968278>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#perturb(test_data, epoch, corpus_test, hybrid=args.hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(data_source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_gen = gan_gen.cpu()\n",
    "inverter = inverter.cpu()\n",
    "autoencoder.eval()\n",
    "autoencoder = autoencoder.cpu()\n",
    "autoencoder.gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise, hypothesis, target, premise_words, hypothesise_words, lengths = batch\n",
    "\n",
    "c = autoencoder.encode(hypothesis, lengths, noise=False)\n",
    "z = inverter(c).data.cpu()\n",
    "\n",
    "batch_size = premise.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "premise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,    94,  5586,  6924,   331,  3110,  4207,  6319,  9074,    22],\n",
       "        [    1,    94,  5586,  6924,   331,  3110,  4207,  6319,  9074,    22],\n",
       "        [    1,    94,  5586,  6924,   331,  3110,  4207,  6319,  9074,    22],\n",
       "        [    1,  9806,  3560,  2038,  6404,  6282,  9350,  9131,    22,     2],\n",
       "        [    1,  9806,  3560,  2038,  6404,  6282,  9350,  9131,    22,     2],\n",
       "        [    1,    94,  8768,  6319,    94, 10755,  6888,  6282,  8762,     2],\n",
       "        [    1,    94,  8768,  6319,    94, 10755,  6888,  6282,  8762,     2],\n",
       "        [    1,    94,  8768,  6319,    94, 10755,  6888,  6282,  8762,     2],\n",
       "        [    1,   331,  6310, 10844,  9710,  9883,    94,  3895,    22,     2],\n",
       "        [    1,   331,  6310, 10844,  9710,  9883,    94,  3895,    22,     2]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "premise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,    94,  5586,  6924,   734,  6319,  9754,  3657,    22,     0],\n",
       "        [    1,    94,  5586,  6924,  4207,  6319,  9074,    22,     0,     0],\n",
       "        [    1,    94,  5586,  4885,  6747,  3733,  1598,    22,     0,     0],\n",
       "        [    1,  9806,  3561,  2054, 10309,  3828,    94,  9350,  9131,    22],\n",
       "        [    1,  9806,  3561,  6924,  1548,  4799,    94,  3556,  9131,    22],\n",
       "        [    1,    94,  8762,  3503, 10827,    94,  8768,  6319,  4895,     0],\n",
       "        [    1,    94,  8768,  3999,  6427,    94,  3503,  6282,  8762,     0],\n",
       "        [    1,    94,  8780,  4734,    94,  1031,     0,     0,     0,     0],\n",
       "        [    1,  9754,  5172,  4885,  2221,  2730,     0,     0,     0,     0],\n",
       "        [    1,  9754,  5172,  4885, 10667,  4435,  3895,     0,     0,     0]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 1, 0, 2, 0, 1, 1, 2, 1])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 8, 8, 10, 10, 9, 9, 6, 6, 7]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 300])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> a man playing an electric guitar on stage .\n",
      "<sos> a man playing banjo on the floor . <pad>\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "print(' '.join(premise_words[n]))\n",
    "print(' '.join(hypothesise_words[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'entailment':0, 'neutral':1, 'contradiction':2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_fn(data):\n",
    "    # query baseline classifiers with sentence pairs\n",
    "    gpu = args.cuda\n",
    "    premise, hyp_indices, hypothesis_c, dist = data\n",
    "    edit_dist = []\n",
    "    premise_words = \" \".join(\n",
    "        [corpus_test.dictionary.idx2word[x] for x in premise.data.cpu().numpy()[0]])\n",
    "    premise_words_indices1 = [vocab_classifier1[w] if w in vocab_classifier1 else 3 for w in\n",
    "                              premise_words.strip().split()]\n",
    "    premise_words_indices1 = Variable(torch.LongTensor(premise_words_indices1)).unsqueeze(0)\n",
    "\n",
    "    premise_words_indices2 = [vocab_classifier2[w] if w in vocab_classifier2 else 3 for w in\n",
    "                              premise_words.strip().split()]\n",
    "    premise_words_indices2 = Variable(torch.LongTensor(premise_words_indices2)).unsqueeze(0)\n",
    "\n",
    "    hyp_sample_idx = autoencoder.generate(hypothesis_c, 10, True).data.cpu().numpy()\n",
    "    words_all = []\n",
    "    premise_word_inds1 = []\n",
    "    premise_word_inds2 = []\n",
    "    hypothesis_word_inds1 = []\n",
    "    hypothesis_word_inds2 = []\n",
    "    for i in range(hyp_sample_idx.shape[0]):\n",
    "        words = [corpus_test.dictionary.idx2word[x] for x in hyp_sample_idx[i]]\n",
    "        words_all.append(\" \".join(words) + \"\\t\" + str(dist[i]))\n",
    "\n",
    "        edit_dist.append(\n",
    "            len(set(hyp_indices[0].data.cpu().numpy()).intersection(set(hyp_sample_idx[0]))))\n",
    "        hypothesis_word_indx1 = [vocab_classifier1[w] if w in vocab_classifier1 else 3 for w in\n",
    "                                 words]\n",
    "        hypothesis_word_indx1 = Variable(torch.LongTensor(hypothesis_word_indx1)).unsqueeze(0)\n",
    "        hypothesis_word_indx2 = [vocab_classifier2[w] if w in vocab_classifier2 else 3 for w in\n",
    "                                 words]\n",
    "        hypothesis_word_indx2 = Variable(torch.LongTensor(hypothesis_word_indx2)).unsqueeze(0)\n",
    "        if gpu:\n",
    "            premise_words_indices1 = premise_words_indices1.cuda()\n",
    "            premise_words_indices2 = premise_words_indices2.cuda()\n",
    "            hypothesis_word_indx1 = hypothesis_word_indx1.cuda()\n",
    "            hypothesis_word_indx2 = hypothesis_word_indx2.cuda()\n",
    "\n",
    "        premise_word_inds1.append(premise_words_indices1)\n",
    "        premise_word_inds2.append(premise_words_indices2)\n",
    "        hypothesis_word_inds1.append(hypothesis_word_indx1)\n",
    "        hypothesis_word_inds2.append(hypothesis_word_indx2)\n",
    "\n",
    "    premise_word_inds1 = torch.cat(premise_word_inds1, 0)\n",
    "    premise_word_inds2 = torch.cat(premise_word_inds2, 0)\n",
    "    hypothesis_word_inds1 = torch.cat(hypothesis_word_inds1, 0)\n",
    "    hypothesis_word_inds2 = torch.cat(hypothesis_word_inds2, 0)\n",
    "\n",
    "    prob_distrib1 = classifier1((premise_word_inds1, hypothesis_word_inds1))\n",
    "    prob_distrib2 = classifier2((premise_word_inds2, hypothesis_word_inds2))\n",
    "\n",
    "    _, predictions1 = torch.max(prob_distrib1, 1)\n",
    "    _, predictions2 = torch.max(prob_distrib2, 1)\n",
    "\n",
    "    return predictions1, predictions2, words_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/guojy/natural-adversary/textSNLI/search.py:36: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  perturb_z = Variable(mus + delta, volatile=True)\n",
      "/local/guojy/anaconda3/envs/pt1/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    }
   ],
   "source": [
    "x_adv1, x_adv2, d_adv1, d_adv2, all_adv = search_fast(\n",
    "    gan_gen, pred_fn, (premise[n].unsqueeze(0), hypothesis[n].unsqueeze(0)),\n",
    "    target[n], z[n].view(1, 100))\n",
    "\n",
    "hyp_sample_idx1 = autoencoder.generate(x_adv1, 10, True).data.cpu().numpy()[0]\n",
    "hyp_sample_idx2 = autoencoder.generate(x_adv2, 10, True).data.cpu().numpy()[0]\n",
    "words1 = [corpus_test.dictionary.idx2word[x] for x in hyp_sample_idx1]\n",
    "words2 = [corpus_test.dictionary.idx2word[x] for x in hyp_sample_idx2]\n",
    "if \"<eos>\" in words1:\n",
    "    words1 = words1[:words1.index(\"<eos>\")]\n",
    "if \"<eos>\" in words2:\n",
    "    words2 = words2[:words2.index(\"<eos>\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'street waiting on huge very knitting on music waiting outside'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(words1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foot very very band waiting on very waiting new on'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> a man playing an electric guitar on stage .\n",
      "<sos> a man playing banjo on the floor . <pad>\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(premise_words[n]))\n",
    "print(' '.join(hypothesise_words[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'287144': 'A kid is doing a jump at the basketball court .',\n",
       " '287145': 'A kid is riding a bike at the courts .',\n",
       " '287146': 'Little boy playing with his toy truck .',\n",
       " '287147': 'A boy plays in a sandbox .',\n",
       " '287140': 'Cyclists are talking to each other',\n",
       " '287141': 'A group of men cycling on the moon .',\n",
       " '287142': 'A youth riding a skateboard is airborne amongst the basketball courts .',\n",
       " '287143': 'A kid on a skateboard is outside .',\n",
       " '611459': 'Cyclists trying to blast past the leader who is wearing an orange and white shirt',\n",
       " '287148': 'A boy plays with a toy .',\n",
       " '287149': 'A guy in blue jeans with a black shirt has his hand in his pocket .',\n",
       " '378468': 'Messi practices his dribbling .',\n",
       " '378469': 'A waffle learns to speak .',\n",
       " '89370': 'The boy is playing in the grass',\n",
       " '89371': 'The boy is sleeping',\n",
       " '89372': 'A child is wearing glasses',\n",
       " '89373': 'A man in a neon shirt , khakis , and an orange hard hat walks by a mulch machine .',\n",
       " '89374': 'A woman is playing Mario Kart .',\n",
       " '89375': 'A man walks by a mulch machine after deciding not to buy any .',\n",
       " '89376': 'A construction worker in a hard hat wearing a lime green shirt .',\n",
       " '89377': 'A man works in construction',\n",
       " '89378': \"The man is a member of the Village people singing `` YMCA ''\",\n",
       " '89379': \"a consutruction work is celebrating st. Patrick 's day\",\n",
       " '622345': 'A dog doggie-paddles in the water .',\n",
       " '647235': 'A child is doing gymnastics in front of a crowd .',\n",
       " '370259': 'A man is smoking on the back of a truck',\n",
       " '370258': 'A man stands on the back of a trash truck .',\n",
       " '378463': 'A young boy kicks a ball as he runs through grass .',\n",
       " '548401': 'A man is sitting in thought on rock ledges .',\n",
       " '5988': \"Water is shooting in the white dog 's face .\",\n",
       " '5989': 'The dog is white .',\n",
       " '378467': 'a person kicking around a soccer ball .',\n",
       " '378460': 'A boy kicking a ball',\n",
       " '548400': 'A man is sitting on rock ledges .',\n",
       " '5982': 'The pet remains dry after being hit from behind with a pail of water .',\n",
       " '5983': 'The dog is being squirted',\n",
       " '5980': 'The dog enjoys being sprayed with water .',\n",
       " '5981': 'A dogs butt is being squirted with water .',\n",
       " '5986': 'The dog with a light-colored coat its muzzle wet with a stream of water .',\n",
       " '5987': 'He is outside',\n",
       " '5984': 'A child is squirting the dog with a water gun .',\n",
       " '5985': 'He is drinking water .',\n",
       " '548402': 'An artist works diligently at painting a piece of ornate pottery .',\n",
       " '623484': 'They are waiting for their table to be ready at a restaurant .',\n",
       " '635778': 'A group of dogs are chasing a duck .',\n",
       " '635779': 'Some kids are playing on a swing at a park .',\n",
       " '635776': 'A short person in a uniform',\n",
       " '548405': 'a man makes his first pottery',\n",
       " '628403': 'A young girl drinks cement .',\n",
       " '635775': 'A woman wearing a martial arts uniform holds her sneakered foot with both hands over her head .',\n",
       " '635772': 'A tall person carrying cases',\n",
       " '635773': 'A person carrying cases',\n",
       " '635770': 'A little boy is jumping around and falls off a balcony .',\n",
       " '548404': 'a human making pottery',\n",
       " '649511': 'A group of men looking at fishing poles .',\n",
       " '218135': 'A woman is searching .',\n",
       " '378464': 'The boy is in a parking lot .',\n",
       " '649512': 'A group of women looking at laptops together .',\n",
       " '649515': 'Women are shopping for Dell Computers .',\n",
       " '548407': 'Someone poses for a photo in the woods .',\n",
       " '649517': 'A dad with his child and an apple pie .',\n",
       " '218134': 'A woman is searching for her purse',\n",
       " '649519': 'A dad and his child are eating apple pie .',\n",
       " '649518': 'A dad and his daughter with an blueberry pie .',\n",
       " '548406': 'A man in a blue shirt and jeans poses by large mossy rocks .',\n",
       " '360605': 'Kids are watching two adults lying on a mattress .',\n",
       " '559008': \"The people are performing a musical for this week 's concert .\",\n",
       " '73624': 'a boy does a skateboard trick',\n",
       " '378465': 'Someone is kicking a ball that is multicolored .',\n",
       " '370255': 'A man looks up at shredded paper',\n",
       " '370254': 'A large amount of paper has been shredded .',\n",
       " '494920': 'There are long , red , padded benches .',\n",
       " '494921': 'There are long , light red , padded benches .',\n",
       " '494922': 'The benches can each seat 3 people .',\n",
       " '494923': 'Three females , one in pink and blue , another in a multicolored skirt with blue belt , and a final in white with a red umbrella are walking .',\n",
       " '494924': 'The females are going to lunch .',\n",
       " '370257': 'A man looks at a pile of paper that he has shredded at work .',\n",
       " '494926': 'Old man sitting on a red bench looking at a blank screen .',\n",
       " '494927': 'The blank screen is intentional /',\n",
       " '634195': 'A male is in a white shirt',\n",
       " '638078': 'A woman is using Frisbees to play with a dog in front of a stadium crowd and a group of baseball players .',\n",
       " '370256': 'The man is looking at stuffed animals .',\n",
       " '651858': 'A young girl flips an omelet .',\n",
       " '638072': 'A goalie in the World Cup .',\n",
       " '370251': 'A man looks at paper .',\n",
       " '638070': 'The guys in jackets and hats are cutting trees .',\n",
       " '638071': \"A goalie braces himself for the ball that 's coming his way .\",\n",
       " '638076': 'a young boy and girl kiss near hay and autumn display',\n",
       " '445703': 'There are people watching karate',\n",
       " '378462': 'a teenager playing basketball',\n",
       " '370250': 'The man is looking at old bills .',\n",
       " '370253': 'A man looks down at shredded paper',\n",
       " '641612': 'a guy with a blue top carries a pack and makes his way through snow',\n",
       " '445638': 'Dirt bikers competing for a championship .',\n",
       " '218139': 'A man kneeling with posters',\n",
       " '370252': 'A man looks down at blue shredded paper',\n",
       " '391277': 'A group of people eat cheese sticks .',\n",
       " '218138': 'A man standing with a gym bag',\n",
       " '16709': 'the man is inside leaning on a wall',\n",
       " '16708': 'a man is sitting on a bench',\n",
       " '584484': 'Man jogging on a rainy day .',\n",
       " '16705': 'A man is stealing candy .',\n",
       " '16704': 'A person is waiting for someone .',\n",
       " '16707': 'A man with a shirt on his head , wearing a plaid shirt , leaning against a painted blue wall .',\n",
       " '16706': 'A person is wearing a head wrap .',\n",
       " '16701': 'man standing against blue wall',\n",
       " '16700': 'man quietly standing against blue wall with shirt on head',\n",
       " '16703': 'A man in a black head wrap is standing against a blue wall .',\n",
       " '16702': 'man running near blue wall',\n",
       " '583930': 'the officer is naked and sleeping',\n",
       " '494313': 'A group of young people actively jumping into the air with arms up and outward in different directions with legs bent and extended to positions of motion .',\n",
       " '583932': 'A man dancing with two woman in lingerie .',\n",
       " '583933': 'A man watching a poster in his uniform .',\n",
       " '583934': 'A man enjoying what he is looking in the poster with woman in lingerie .',\n",
       " '549758': 'People huddle in a doorway to stay out of the rain .',\n",
       " '583936': 'A guide takes a lunch break .',\n",
       " '494312': 'A group of old people scowl at the young man taking their picture',\n",
       " '583938': 'A guide points to a deer .',\n",
       " '583939': 'A group of about 11 people of all ages with binoculars in the woods',\n",
       " '319693': 'man looking for a book in a library while a woman blows her nose because she has a bad cold .',\n",
       " '101358': 'A young couple are on a date .',\n",
       " '425873': 'A golden retriever is shaking off some water',\n",
       " '622344': 'Two dogs leap off a dock into the water .',\n",
       " '549756': 'Two teenagers huddle in a doorway in the rain .',\n",
       " '316995': 'The person is floating in the water .',\n",
       " '119869': 'An old woman and a young girl are standing on the deck of a boat .',\n",
       " '119868': 'Racecar goes off the track of a race course',\n",
       " '353520': 'The baby is smiling in the chair .',\n",
       " '119865': 'Toyota Rally car plows through a deep puddle of mud on the race course .',\n",
       " '119864': 'A car running in the muddy area .',\n",
       " '119867': 'Monster truck runs over 100 cars',\n",
       " '119866': 'Rally car wrecks after hitting a deep puddle of mud',\n",
       " '119861': 'A car drives through a muddy area on a dirt track , spraying water and mud everywhere .',\n",
       " '119860': 'Three young people are sitting in the grass .',\n",
       " '119863': 'A car is standing in the car shed .',\n",
       " '119862': 'A car is spraying water when it drives .',\n",
       " '549755': 'The man is jumping to catch a balloon that escaped .',\n",
       " '316990': 'The girl is folding towels .',\n",
       " '549752': 'The guy hurt his feet on the pile of rocks out in the field .',\n",
       " '316991': 'A female is cleaning the sink .',\n",
       " '549753': 'A man who is wearing a green shirt and brown pants , appears to be very exciting , jumping in the air with his hands raised .',\n",
       " '101352': 'Two people play hockey .',\n",
       " '460587': 'Girls are having food in sunlight .',\n",
       " '117639': 'A man is looking for some dank weed to smoke in his pipe .',\n",
       " '353521': 'The baby is a statue made from orange peels .',\n",
       " '101353': 'A small brown dog plays with a ball on the beach .',\n",
       " '378461': 'a teenager playing soccer',\n",
       " '373363': 'A man is making a craft .',\n",
       " '549751': \"There 's a black guy jumping around in the field .\",\n",
       " '101350': 'Two women are indoors .',\n",
       " '463009': 'Men playing softball outside .',\n",
       " '463008': 'Football players playing outside and man catch flying ball .',\n",
       " '554374': 'A young boy with bowed head .',\n",
       " '101351': 'Two women are on the same team .',\n",
       " '554372': 'A young boy prays for his food before his meal .',\n",
       " '554373': 'A boy bows toward an authority figure .',\n",
       " '353269': 'In the middle of a shopping center , there is a man who is painted gold with a gold bicycle .',\n",
       " '353268': 'A man is on his gold bike .',\n",
       " '353267': 'A man has a bike with him .',\n",
       " '101356': 'A dog plays with a ball that it found in the water .',\n",
       " '353265': 'A man is flying an airplane over the city .',\n",
       " '353264': 'The man wanted to get a good view of the city .',\n",
       " '353263': 'Man is driving a green Ferrari towards Ohio',\n",
       " '353262': 'A man has a gold bike .',\n",
       " '353261': 'The city stopped to look at the man .',\n",
       " '101357': 'A man takes salad out of a bowl while he sits at a table with other plates , a woman , a glass of wine , and a decorative curtain behind him .',\n",
       " '86384': 'A little kid is playing with a kite on the beach .',\n",
       " '306948': 'The doctor is trying to fix the X-ray machine .',\n",
       " '306949': 'The man is trying to fix the problem .',\n",
       " '306944': 'A small crowd of people are walking around a woman wearing an orange wig and a long blue dress .',\n",
       " '306945': 'A large crowd of people are walking',\n",
       " '306946': 'A large crowd of people are walking around a tall woman wearing an orange wig and a long blue dress .',\n",
       " '306947': 'The man in the white coat is trying to diagnose the problem so that he can fix it and get the machine running again .',\n",
       " '306940': 'A man is coughing while operating machinery .',\n",
       " '306941': 'A man coughing .',\n",
       " '306942': 'A man working hard while coughing .',\n",
       " '306943': 'A large crowd of people are walking around a woman wearing an orange wig and a long blue dress .',\n",
       " '168083': 'The women perform for the first time together .',\n",
       " '168082': 'A trio of women juggling wearing white outfits with angel wings',\n",
       " '168081': 'Peoople sing',\n",
       " '168080': 'The two African Americans are men .',\n",
       " '168087': 'Two black men .',\n",
       " '168086': 'Two African American males smiling for a camera .',\n",
       " '168085': 'Two African American males looking into the camera while their photo is taken .',\n",
       " '168084': 'Women are performing together .',\n",
       " '168089': 'Two caucasion men looking into a camera .',\n",
       " '168088': 'Two African American males taking a picture together .',\n",
       " '445700': 'A group of children doing karate .',\n",
       " '160258': 'The person is sitting on the ground with candy near her .',\n",
       " '160259': 'A person in a green shirt is standing near a fence .',\n",
       " '160256': 'A person in a green shirt is sitting on the ground near a fence , with fruit laid out near her .',\n",
       " '160257': 'A woman plants a tree in the middle of a field .',\n",
       " '160254': 'A young boy is eating an apple while strolling through a market .',\n",
       " '160255': 'A young boy is wearing a dress selling fruits .',\n",
       " '160252': 'A young boy sitting around a bunch of fruits , might be selling some of them .',\n",
       " '160253': 'A young boy sits near produce .',\n",
       " '160250': 'a girl is jumping rope',\n",
       " '160251': 'a boy on the ground sells fruit',\n",
       " '645848': 'a dog catching a ball',\n",
       " '464477': 'A female animal is being groomed .',\n",
       " '494683': 'A girl at twilight .',\n",
       " '641764': 'The young girl is having fun .',\n",
       " '584487': 'There are many people togther inside .',\n",
       " '362708': 'The band performs on stage .',\n",
       " '320500': 'The bird is attacking the children .',\n",
       " '320501': 'The bird is trying to find nectar .',\n",
       " '320502': 'A group of four girls meets with a group of elderly women .',\n",
       " '320503': 'The people meets the group',\n",
       " '320504': 'The biker does a trick in the air .',\n",
       " '320505': 'the biker ride on the water',\n",
       " '320506': 'the biker does a trick in the air for circus',\n",
       " '320507': 'the biker does a trick in the air for money',\n",
       " '320508': 'An older woman in all gray is looking into the view screen of a digital camera .',\n",
       " '320509': 'A woman is a professional photographer .',\n",
       " '488787': 'People in transitional Indian dress attire are bathing in a river .',\n",
       " '488786': 'A crowd of women are currently traveling together through a forest',\n",
       " '488781': 'A woman is washing herself in front of others .',\n",
       " '488780': 'A crowd of women are knitting at a store',\n",
       " '488783': 'The women are in a kitchen .',\n",
       " '488782': 'A group of boys are playing with goats .',\n",
       " '494682': 'A girl digging up graves at twilight .',\n",
       " '163509': 'A boy carries a box down the street .',\n",
       " '163508': 'The boy is carrying a box full of books .',\n",
       " '163507': 'A boy wearing a hat and backpack walks down the street carrying a box .',\n",
       " '163506': 'A boy in a blue hat and a yellow backpack is carrying a box while walking down the street .',\n",
       " '163505': 'man in backpack',\n",
       " '163504': 'man going to class',\n",
       " '163503': 'girl plays xbox',\n",
       " '163502': 'A rear view of a young man with a brown backpack and cardboard box under left arm walking across a street .',\n",
       " '163501': 'An old man walking in the rain .',\n",
       " '163500': 'A man sitting in a coffee shop .',\n",
       " '513058': 'Two men leave the park .',\n",
       " '513059': 'Two women wave goodbye .',\n",
       " '635777': 'A group of kids are playing on a tire swing .',\n",
       " '513052': 'A wrestler is being held in the air by another man in the ring .',\n",
       " '513053': 'They are wearing wrestling masks',\n",
       " '513050': 'There is a man and a dog outside .',\n",
       " '513051': 'A dog has to go to the bathroom , so his owner took him outside .',\n",
       " '513056': 'Two women , wearing hats , sunglasses , and gloves , wave goodbye .',\n",
       " '513057': 'Two women wave goodbye to their friends .',\n",
       " '513054': 'They are cuddling together in bed watching Netflix',\n",
       " '513055': 'They are competing in a wrestling match',\n",
       " '494685': 'A girl is traveling outside .',\n",
       " '459298': 'Two girls sit on the edge of a river .',\n",
       " '559848': 'A man is leaving a dingy diner .',\n",
       " '635771': 'A young women carrying some wooden cases , walking down the street and passing a street performer .',\n",
       " '617547': 'The people are riding along a deserted beach .',\n",
       " '494684': 'Girl reading book walking down street .',\n",
       " '584445': 'The child is a newly adopted child waiting with his new parents before heading home on a plane .',\n",
       " '584444': 'A sleeping baby is sucking his fingers and is wearing an asian outfit .',\n",
       " '584447': 'A baby is sleeping and sucking his finger .',\n",
       " '584446': \"The baby is wide awake and crying for it 's mother .\",\n",
       " '584441': 'A man on the street checks out an orange sports car .',\n",
       " '584440': 'A manin a meeting room is looking at a chart on a presentation board .',\n",
       " '584443': 'A human on the street .',\n",
       " '584442': 'A tall human on the street .',\n",
       " '353527': 'A person wearing a yellow shirt talks to a child .',\n",
       " '584449': 'The baby is playing in a playpen',\n",
       " '584448': 'The baby is lying down .',\n",
       " '212058': 'A girl runs in the street with a puppy .',\n",
       " '459291': 'The man is in a car race',\n",
       " '583741': 'People walking across a bridge .',\n",
       " '459290': 'The man is going to win',\n",
       " '617546': 'Six People riding bikes on a trail in the forest .',\n",
       " '494687': 'A girl is trying to figure out where she is going .',\n",
       " '459293': 'The man and boy are together .',\n",
       " '640258': 'Two young men splitting wood with a axe in the snow .',\n",
       " '649514': 'Women are shopping for computers at a large store .',\n",
       " '559005': 'people at a concert',\n",
       " '459292': 'man and boy building with wood',\n",
       " '640363': 'A person is playing soccer',\n",
       " '459295': 'The man and boy are using tools .',\n",
       " '649516': 'Women are shopping at safeway for lamb chops .',\n",
       " '212059': 'A female child , in the road , with a toy .',\n",
       " '459294': 'The man and boy are playing with Legos .',\n",
       " '583740': 'A man walks down a street as a white van zooms by',\n",
       " '585779': 'A little girl and a little boy playing on a bouncy ride .',\n",
       " '459297': 'The helmet is large .',\n",
       " '620197': 'A man with a cane enjoys walking near art .',\n",
       " '617541': 'A man and a woman are sitting on a beach',\n",
       " '494686': 'A girl is sitting down , looking at the ceiling .',\n",
       " '459296': 'A man in a black shirt and white helmet riding a bike over rocky ground .',\n",
       " '638721': 'A man and his son put camouflage greasepaint on their faces before they go hunting .',\n",
       " '584486': 'A crowd waits to interact with some people in an indoor location .',\n",
       " '581579': 'children playing water polo',\n",
       " '303231': 'A person is laying on the ground trying to take the perfect picture .',\n",
       " '303230': 'A person got knocked to the ground by a giant bird with a backpack .',\n",
       " '303233': 'The little girl in the red flowered dress and pink cape is holding a racket .',\n",
       " '303232': 'A person in a plaid shirt is standing near a backpack .',\n",
       " '303235': 'The little girl is wearing blue jeans .',\n",
       " '303234': 'The little girl is holding a tennis racket .',\n",
       " '303237': 'A group of men in blue uniforms are standing together .',\n",
       " '303236': 'The racket is not too heavy for the little girl to hold .',\n",
       " '303239': 'a group of cops standing together',\n",
       " '303238': 'a group of men in standing .',\n",
       " '622342': 'man is wearing the hat while watching the cricket .',\n",
       " '495897': 'Man in Dr Pepper logo shirt laying on a blue blanket , with arm around a toy-chewing infant .',\n",
       " '495896': 'A man is laying with a baby .',\n",
       " '495895': 'A girl is doing cartwheels .',\n",
       " '495894': 'A man is spending time with his newborn .',\n",
       " '495893': 'A man with a beard in a Dr. Pepper t-shirt is laying on a blue blanket with a baby .',\n",
       " '495892': 'A man and baby have been playing .',\n",
       " '495891': 'A woman holds a baby while she stands outside .',\n",
       " '495890': 'A man relaxing with a baby on a blanket .',\n",
       " '495899': 'man with infant',\n",
       " '495898': 'man just had first son',\n",
       " '388670': 'The people are sitting together at a table with another facing away .',\n",
       " '388671': 'A girl sitting on a bench reading a magazine .',\n",
       " '388672': 'The girl is napping on the bench .',\n",
       " '388673': 'The girl is reading the latest issue of Sports Illustrated',\n",
       " '388674': 'A person sits , reading .',\n",
       " '388675': \"Two women and two women have a meal together in someone 's home .\",\n",
       " '388676': 'the woman ate alone',\n",
       " '388677': 'the women are eating',\n",
       " '388678': 'the women are talking',\n",
       " '388679': 'A woman sleeps on a bus seat .',\n",
       " '605475': 'The woman is teaching her kids how to swim .',\n",
       " '521000': 'Asian people wearing helmet waiting to buy food .',\n",
       " '491828': 'a man sleeps in a hammock',\n",
       " '532444': 'A little girl is running through the sprinkler wearing a clown suit',\n",
       " '532445': 'A little girl is running through the sprinkler',\n",
       " '532446': 'Inuit Indians prepare for winter by building an igloo .',\n",
       " '491829': 'a man sits in a restaurant',\n",
       " '532440': 'On a hot summer day , a child decides to cool off .',\n",
       " '532441': 'A girl wearing bright orange is cooling off in the sprinkler in her backyard .',\n",
       " '532442': 'A dog eating a bird .',\n",
       " '532443': 'A girl playing in her front yard .',\n",
       " '381638': 'A man with a skateboard jumping .',\n",
       " '525399': 'A man is looking out a circular window .',\n",
       " '532448': 'People are playing drums .',\n",
       " '532449': 'People are playing french horns .',\n",
       " '647817': 'A person is climbing a steep cliff .',\n",
       " '257655': 'Two people sit in black folding chairs while others stand around them at a concert .',\n",
       " '257654': 'Two people sit in chairs in the middle of a large standing crowd .',\n",
       " '257657': 'friends went fishing',\n",
       " '257656': 'Two people sit and enjoy themselves along a busy street in lawn chairs as others mill in front of them .',\n",
       " '257651': 'People are in a campground .',\n",
       " '257650': 'People are in a city .',\n",
       " '257653': 'Two people in black folding chairs sit in a waiting room of a hospital .',\n",
       " '257652': 'Two people sit in black folding chairs while everyone else in the crowd stands .',\n",
       " '257659': 'two childhood friends enjoying by sitting along busy street on a lawn chair',\n",
       " '257658': 'two people enjoying by sitting along busy street on lawn chair',\n",
       " '446866': 'A man juggles steak knives .',\n",
       " '634196': 'A group of young men and women are crouched in a circle .',\n",
       " '522239': 'No one is sitting next to a tent .',\n",
       " '456729': 'Two men are drinking outside .',\n",
       " '491823': 'A man in a white shirt talks to a woman in a blue shirt .',\n",
       " '491820': 'The dogs sit on the grass .',\n",
       " '640362': 'A soccer player in a lime green shirt looks down at a yellow soccer ball .',\n",
       " '494928': 'The screen does not show anything .',\n",
       " '491821': 'Two dogs catch frisbees on the beach .',\n",
       " '458330': 'A group of men , one with a large bike , on a dock',\n",
       " '491826': 'A man in a black and white plaid shirt is sitting at a table in the restaurant ordering food .',\n",
       " '570638': \"A woman is wiping a woman 's brow .\",\n",
       " '453863': 'A little girl is being held by a woman .',\n",
       " '353857': 'There are people near an object .',\n",
       " '446867': 'A man juggles apples .',\n",
       " '467598': 'The lady is taking pictures of family .',\n",
       " '491824': 'Two people have an argument over sports .',\n",
       " '491825': 'Two men shout at each other .',\n",
       " '381725': 'The two men are performing on a stage .',\n",
       " '381724': 'Woman singing',\n",
       " '107899': 'A mustachioed man prepares bagels .',\n",
       " '107898': 'A man delivers steaming fajitas to a table .',\n",
       " '381721': 'A man is playing the guitar while another man plays the drums in front of a crowd of people .',\n",
       " '381720': 'A man sells tropical fruit to two other men .',\n",
       " '26568': 'A nude man is sliding down a wooden banister .',\n",
       " '26569': 'A man in blue pants and a blue sweatshirt makes a railing out of wood .',\n",
       " '26566': 'A man is working on a project .',\n",
       " '26567': 'A man is painting the banisters in his house .',\n",
       " '26564': 'The man is building a couch .',\n",
       " '26565': 'A man in a cap , sweatshirt , and jeans works on wooden banisters .',\n",
       " '26562': 'The man is building a treehouse with a hammer .',\n",
       " '26563': 'The man is using a power tool .',\n",
       " '26560': 'Four little boys bang on a set of drums .',\n",
       " '26561': 'A man is working on a piece of furniture with a power tool .',\n",
       " '420101': 'The cheerleaders are doing a half-time show in the outdoor football stadium .',\n",
       " '420100': 'A group of cheerleaders take center court in the gym and perform .',\n",
       " '420103': 'There are cheerleaders in the gymnasium .',\n",
       " '420102': 'The cheerleading squad is co-ed .',\n",
       " '420105': 'The cheerleaders for Stanford are performing .',\n",
       " '420104': 'A cheerleading squad performing for a crowd at a sporting event .',\n",
       " '420107': 'The marching band is trying out cheerleading with their instruments .',\n",
       " '420106': 'These cheerleaders are performing .',\n",
       " '420109': 'their team just scored',\n",
       " '175971': 'Oriental man reading a sheet at a convention .',\n",
       " '609980': 'The two girls are doing acrobatics outside .',\n",
       " '609981': 'One girl is doing a handstand on an indoor trampoline while another girl stands on the trampoline with one hand in the air .',\n",
       " '609986': 'A woman in a green coat is standing by a scope pointed towards the sky .',\n",
       " '609987': 'A woman wearing a green coat and brown boots is standing by a telescope .',\n",
       " '609984': 'A man sitting next to a child on the grass .',\n",
       " '175970': 'A toddler is running towards his mom .',\n",
       " '528929': 'Bikers are racing .',\n",
       " '617348': 'A couple shares cake after their marriage ceremony .',\n",
       " '593785': 'sailor in white shirt',\n",
       " '395129': 'a girl in white is like tennis',\n",
       " '150169': 'The young man was listening to the three other men talk',\n",
       " '150168': 'A young man is sitting on a bench while three other men talk',\n",
       " '150167': 'The young man was running around the bench',\n",
       " '150166': 'A young man is sitting on a bench while three other men talk .',\n",
       " '150165': 'The man is sitting with the others .',\n",
       " '150164': 'They are talking about the man .',\n",
       " '150163': 'Three people are talking together , a man is sitting alone in a bench .',\n",
       " '150162': 'A women watches people walk bye .',\n",
       " '150161': 'I women waiting on friends outside a building .',\n",
       " '150160': 'A women is home alone',\n",
       " '401240': 'Working out in the gym .',\n",
       " '212051': 'A pregnant woman is standing in a kitchen holding her stomach with something in her mouth .',\n",
       " '572080': 'Two young woman are walking on a sidewalk surrounded by other young people .',\n",
       " '572081': 'The two women are college students .',\n",
       " '572082': 'One of the girls is a sumo wrestler .',\n",
       " '572083': 'There are a lot of people on the sidewalk',\n",
       " '570635': 'Two girl are in a crowded place .',\n",
       " '384078': \"The women 's bathing suits are green .\",\n",
       " '572086': 'A mustached man is attempting to use a food processor .',\n",
       " '572087': 'A woman sitting on the ground at a marina .',\n",
       " '572088': 'A woman sitting down outside .',\n",
       " '175979': 'A girl playing in the sink with toys and some potentially dangerous household chemicals .',\n",
       " '384079': 'Some women are in a lake .',\n",
       " '534598': 'A man sits next to his wife .',\n",
       " '175978': 'a woman is modeling new fashion',\n",
       " '520886': 'The young people are dancing at a rave .',\n",
       " '638079': 'The dog is a show dog , entertaining the crowd before the game .',\n",
       " '425689': 'A male is performing martial arts in front of spectators .',\n",
       " '425688': 'Martial artists gather outdoors .',\n",
       " '425685': 'The woman is a champion .',\n",
       " '425684': 'Two women are violently fighting in anger with weapons in front of children and other spectators .',\n",
       " '425687': 'Female black belt martial artists sit around indoors and do nothing because it is raining outside .',\n",
       " '212052': 'The little girl is carrying a pink and blue toy as she walks on the path .',\n",
       " '425681': 'Man playing a violin sitting on a stage in an empty hall with his orchestra mates .',\n",
       " '384074': 'A group of people are standing around on the sidewalk .',\n",
       " '425683': 'Female black belt martial artists performs outside on a gray day with weapon on a mat while spectators and other martial artists including 3 children look on .',\n",
       " '425682': 'Man playing trumpet on the street for dollar bills .',\n",
       " '570634': 'Two girl are in their home sleeping .',\n",
       " '384075': 'People are sitting on the curb .',\n",
       " '536662': 'A woman is wearing a blue headscarf and a blue sweater .',\n",
       " '446863': 'man washing the windows of a skyscraper',\n",
       " '355069': 'A young person built something',\n",
       " '355068': 'A young person shows what he built to his father',\n",
       " '474314': 'Two young children are playing on the beach while a man watches .',\n",
       " '109835': 'Woman with stuffed animal display .',\n",
       " '623915': 'A group of soldiers are standing by a building .',\n",
       " '446860': 'A bonde haired lady on a cruise ship look at the ocean .',\n",
       " '451444': 'A girl is laughing .',\n",
       " '623917': 'A man is trying to talk to some soldiers about signing up .',\n",
       " '638077': 'two kids are paid to kiss',\n",
       " '581165': 'The man is repairing the motorcycle',\n",
       " '581164': 'The man is bent over a car',\n",
       " '581167': 'A man in a red shirt is sitting on a motorcycle .',\n",
       " '581166': 'The woman is bent over the motorcycle',\n",
       " '581161': 'A man is fixing his motorcycle .',\n",
       " '581160': 'A man in a black shirt is bent over a motorcycle .',\n",
       " '581163': 'A man is leaning over a motor bike .',\n",
       " '581162': 'The man is near a motorcycle',\n",
       " '623911': 'A group of soldiers standing outside a building .',\n",
       " '638075': 'a boy kisses another boy',\n",
       " '581169': 'The man is above his motorcycle .',\n",
       " '581168': 'The man is ghost-riding his motorcycle .',\n",
       " '623910': 'Lopsided men arm wrestling for Universal Champion as a volcano violently erupts behind them .',\n",
       " '105639': 'An Asian woman stands at a counter preparing food .',\n",
       " '105638': 'Nobody is reading .',\n",
       " '250384': 'The little girl is made out of rocks .',\n",
       " '250385': 'A little girl is playing with rocks .',\n",
       " '250382': 'There is one young girl in this picture , and she is outside .',\n",
       " '250383': 'A little girl in a white coat plays in a rock garden .',\n",
       " '250380': \"The girl is bored , and is waiting for her brother to come home from his friend 's house so they can play .\",\n",
       " '250381': 'The girl is making homemade Christmas decorations for her family .',\n",
       " '105631': 'Someone with corrective eyewear is reading on furniture which is beside a pathway .',\n",
       " '105630': 'A man with glasses is happily reading a book .',\n",
       " '105633': 'A man with glasses is reading a book .',\n",
       " '105632': 'A person reading',\n",
       " '105635': 'The man is smoking a pipe .',\n",
       " '105634': 'There is a lying person on the sidewalk .',\n",
       " '105637': 'The man is watching a television show .',\n",
       " '105636': 'A tall person reading',\n",
       " '260886': 'Businessman with briefcase walks up beautiful staircase .',\n",
       " '260887': 'Businessman with a cat walks down the stairs .',\n",
       " '260884': 'A man is making a sword .',\n",
       " '260885': 'A blacksmith working .',\n",
       " '260882': 'A man working next to a furnace , surrounded by metal .',\n",
       " '260883': 'A man is picking daisies .',\n",
       " '260880': 'The chef is preparing a meal .',\n",
       " '260881': 'A kid is playing a game .',\n",
       " '309422': 'There are men all over the world .',\n",
       " '309423': 'There is a woman behind the counter in country .',\n",
       " '309420': 'The man is cooking on the sidewalk .',\n",
       " '109833': 'A lady in a toy store .',\n",
       " '309426': 'A man has his own business .',\n",
       " '309427': 'A man is serving good .',\n",
       " '260888': 'A man is going to a meeting .',\n",
       " '260889': 'Businessman with a briefcase walks up a staircase .',\n",
       " '301219': 'A woman supervisor is instructing the male workers .',\n",
       " '301218': 'Children are discussing what game to play .',\n",
       " '623362': 'A dancer wearing white shirt and shorts is photographed by a man also wearing white .',\n",
       " '330909': 'two women are making music in the road .',\n",
       " '330908': 'two men with a boom box are on the sidewalk .',\n",
       " '541582': 'A man putting cement on his foot .',\n",
       " '301211': 'The dog likes the man',\n",
       " '301210': 'The dog is running from the man',\n",
       " '301213': 'A woman with a box stands in a crowd .',\n",
       " '301212': 'The dog belongs to the man',\n",
       " '301215': 'A woman with a black hat is standing in a crowd .',\n",
       " '301214': 'A person is playing a video game .',\n",
       " '301217': 'Four people are talking .',\n",
       " '301216': 'Three men and a woman standing and having a conversation .',\n",
       " '351690': 'A white german shepherd is laying on the dirt .',\n",
       " '351691': 'A dog running in a public park .',\n",
       " '351692': 'A dog wearing a blue shirt is running and jumping through the air .',\n",
       " '351693': 'there is a dog in this picture',\n",
       " '351694': 'the dog is directing the symphony',\n",
       " '351695': 'the dog is part of a circus',\n",
       " '351696': 'A dog with a muzzle and blue jacket runs around the yard .',\n",
       " '351697': 'A black dog wearing a blue shirt is jumping in the air',\n",
       " '351698': 'The dog is leaping at the throat of his owner , who has humiliated him by dressing him in human clothes .',\n",
       " '351699': \"The dog jumps because he 's well dressed .\",\n",
       " '541586': 'A mustached man attempts to chisel away at a concrete pillar .',\n",
       " '343271': 'a man jumps across an obstacle carrying his bike',\n",
       " '343270': 'A man in red pajamas is jumping , while holding a bicycle .',\n",
       " '343273': 'A bicycler jumping over a barrier with his bike .',\n",
       " '343272': 'A man is shooting fish in a barrel .',\n",
       " '343275': 'A boy riding his bike through the park .',\n",
       " '343274': 'A person on a bicycle is jumping a barrier .',\n",
       " '343277': 'Somebody is jumping a bike .',\n",
       " '343276': 'A biker is vaulting over a hurdle .',\n",
       " '343279': 'A boy on his bike jumping over the barrier .',\n",
       " '343278': 'A cyclist dodges the blockage on his way to work .',\n",
       " '541584': 'A man is scraping cement off foot',\n",
       " '386845': 'A cheerleader holds a tiny girl in the air .',\n",
       " '212057': 'A young female smiles with a doll while roaming .',\n",
       " '386847': 'A cheerleader performs a hand stand at the game .',\n",
       " '386846': 'A cheerleader holds a girl in the air .',\n",
       " '386841': 'Two athletic women warm up before their matches .',\n",
       " '386840': 'The woman has boxing gloves on .',\n",
       " '386843': 'The women do not participate in sports .',\n",
       " '109831': 'Lady in a stuffed animal store .',\n",
       " '570633': 'A girl in a white shirt holds a towel over another girls face as she drinks from a cup in a crowded place .',\n",
       " '415488': 'A group of friends walked along the meadow .',\n",
       " '432808': 'A man sits next to a cat .',\n",
       " '386849': 'A woman is working out at the gym with friends .',\n",
       " '386848': 'A woman is participating in a workout class involving kickboxing-style movements .',\n",
       " '415489': 'The colleagues like to walk on grassy paths .',\n",
       " '640255': 'A girl is sitting by the campfire .',\n",
       " '286235': 'The characters are walking in sand .',\n",
       " '620658': 'The men and women are trying out for a movie role .',\n",
       " '286234': 'A street performer crosses the street .',\n",
       " '571745': 'The couple is walking down a busy street .',\n",
       " '286237': 'A man is cleaning a diving board .',\n",
       " '265108': 'A man is playing baseball with his son .',\n",
       " '265109': 'A man is underwater .',\n",
       " '408295': 'The people are standing by the stairs .',\n",
       " '286236': 'People are using stilts .',\n",
       " '408293': 'On wooden steps leading to a porch , a blond woman in denim shorts sits next to another person whose face is obscured by a baseball cap .',\n",
       " '408292': 'A man is yelling on the phone .',\n",
       " '408291': 'A man uses his cellphone besides a fountain with some philosophy scrawled on its steps .',\n",
       " '408290': 'A woman and man are on their way to work .',\n",
       " '265100': 'There is no one here .',\n",
       " '286231': 'The bike is a tandom bike .',\n",
       " '265102': 'A painter on a ladder paints the brick exterior blue .',\n",
       " '265103': 'The painter has been hired to work thru the week .',\n",
       " '265104': 'A painter on a ladder paints the brick exterior green .',\n",
       " '265105': 'There is a painter on a ladder .',\n",
       " '265106': 'A man underwater with a funny face .',\n",
       " '265107': 'A man is enjoying a day at the pool with his family .',\n",
       " '15708': 'The woman is a Muslim .',\n",
       " '15709': 'The woman is religious .',\n",
       " '295516': 'He wants something .',\n",
       " '295517': 'The man has two hands .',\n",
       " '295510': 'A worker in walmart is dressed up',\n",
       " '295511': 'A man in a white shirt holding both hands out .',\n",
       " '295512': 'He is asking for food .',\n",
       " '295513': 'The man is asking for something .',\n",
       " '15700': 'Women are observing a power point presentation .',\n",
       " '15701': 'Women are observing at a meeting .',\n",
       " '15702': 'A boy is playing on his phone .',\n",
       " '15703': 'A man wearing overalls and a hat is playing acoustic guitar outside .',\n",
       " '15704': 'A guitar player in overalls and a hat plays outside .',\n",
       " '15705': 'A cowboys plays his guitar outside .',\n",
       " '15706': 'A guitar player sleeps inside the bar .',\n",
       " '15707': 'A woman in a headscarf is kneeling on the ground praying .',\n",
       " '417709': 'Hiker climbing down a snow and rock covered mountain .',\n",
       " '259474': 'A group of men on an active construction site .',\n",
       " '415482': 'Three people are enjoying an afternoon',\n",
       " '239541': 'There are six people planting something in the ground .',\n",
       " '620707': 'Two sisters are walking in a desert .',\n",
       " '415483': 'Two men dressed in dark clothing sitting and conversing with each other .',\n",
       " '259472': 'A group of people build a wall for an industrial building .',\n",
       " '24146': 'The little boy is at the side of the river throwing rocks .',\n",
       " '24147': 'A boy is bored outdoors .',\n",
       " '24144': 'A man reads a book .',\n",
       " '24145': 'A child holds a piece of driftwood .',\n",
       " '24142': 'A child in a blue shirt is holding something in his hand on a lake shore .',\n",
       " '24143': 'A child holds something in his hand .',\n",
       " '24140': 'The boy is carrying something in his hand .',\n",
       " '24141': 'The boy wants to throw the stone into the water .',\n",
       " '233033': 'A little girl is rolling a red ball .',\n",
       " '233032': 'A child is running with a bowling ball .',\n",
       " '233031': 'A young child is rolling a ball down the lane in a bowling alley .',\n",
       " '233030': 'Young children playing with marbles',\n",
       " '233037': 'There are people gathered together .',\n",
       " '233036': 'There are five woman and two men in the group .',\n",
       " '24148': 'A boy plays video games .',\n",
       " '24149': 'Several young adults drinking alcoholic beverages at a party .',\n",
       " '596921': 'A dog jumping over hurdles .',\n",
       " '596920': 'The dog is jumping over a yellow and white fence on an obstacle course .',\n",
       " '596923': 'A bunch of younger people are lying and sitting n blankets in the grass .',\n",
       " '596922': 'A brown animal jumping .',\n",
       " '596925': 'The younger people are inside the house .',\n",
       " '596924': 'The younger people are outside on the grass .',\n",
       " '596927': 'A mustached man in a white shirt is at a stand that displays cigarettes and glass bottles of various sodas .',\n",
       " '596926': 'The younger people are having a picnic .',\n",
       " '596929': 'The man is about to buy a bottle of Coke .',\n",
       " '364416': 'A man using binoculars .',\n",
       " '364417': 'A man looking for a bird with binoculars .',\n",
       " '323053': 'A group of people strolling in a city street at night outside .',\n",
       " '507627': 'A man is playing his guitar .',\n",
       " '54279': 'A water truck is releasing water in the air .',\n",
       " '323052': 'A group of people drawing a picture of buildings .',\n",
       " '576543': 'The man is not protesting .',\n",
       " '54278': 'The rainbow is pretty .',\n",
       " '565575': 'She is keeping the dandelion greens as well , as they are a tasty meal .',\n",
       " '323051': 'A group of people strolling in a city street at night toward a night club .',\n",
       " '11847': 'The woman is protesting for equality .',\n",
       " '298649': 'A girl is sitting in a car .',\n",
       " '298648': 'A girl in a magenta dress fixes her hair near a car .',\n",
       " '398088': 'A dog is returning a frisbee to his owner .',\n",
       " '11846': 'The woman is indoors .',\n",
       " '298643': 'The children are ready to eat .',\n",
       " '298642': 'The children are in bed .',\n",
       " '298641': 'The children are waiting for Thanksgiving dinner .',\n",
       " '298640': 'A group of 6 children varying in age from 7 to 14 are sitting around a dinner table ready to eat .',\n",
       " '298647': \"The children are at a family party and are sitting at the kid 's table .\",\n",
       " '298646': 'The children are sitting down to a meal .',\n",
       " '298645': 'The table is round .',\n",
       " '298644': 'Six children sitting around a rectangular dining table with a green tablecloth and food on it .',\n",
       " '136857': 'The child and man are running .',\n",
       " '136856': 'The child is with his dad .',\n",
       " '136855': 'A child is skateboarding while a man is riding his bike .',\n",
       " '136854': 'The two people are friends .',\n",
       " '136853': 'The male knows how to ride a bike .',\n",
       " '136852': 'The male rides a blue bike .',\n",
       " '136851': 'the man is driving go carts',\n",
       " '136850': 'People are riding vehicles .',\n",
       " '11843': 'Dogs gathered together in a dark room .',\n",
       " '323054': 'A man and two women dressed in costumes .',\n",
       " '136859': 'The kid is doing a trick',\n",
       " '136858': 'Kid doing a skateboard trick and an older kid riding a bike .',\n",
       " '11841': 'People gathered together in a dark room .',\n",
       " '157249': 'A woman in orange is working beside a loom .',\n",
       " '157248': 'A woman in orange works beside a loom .',\n",
       " '157247': 'The girl is sliding into second base .',\n",
       " '157246': 'A girl is running towards a base .',\n",
       " '157245': 'A girl plays softball .',\n",
       " '157244': 'A girl is sliding into the base during a softball game .',\n",
       " '157243': 'A woman buys clothes at a store .',\n",
       " '157242': 'A woman with a homemade orange dress makes more orange yarn .',\n",
       " '157241': 'A woman working with yarn .',\n",
       " '157240': 'A woman in an orange dress is dying yarn .',\n",
       " '323058': 'A man wearing a black shirt is outside walking with a shopping cart .',\n",
       " '390491': '5 people are sitting inside a building .',\n",
       " '650144': 'A man in a blue shirt stands by a grill .',\n",
       " '623520': \"A little girl riding on a man 's shoulders .\",\n",
       " '645847': 'a man eating popcorn',\n",
       " '604659': 'These two people are drinking water .',\n",
       " '604658': 'These two people are eating .',\n",
       " '604651': 'A group of friends lean against a railing .',\n",
       " '604650': 'Three people lean against a railing and look at buildings across the water .',\n",
       " '604653': 'A group lean against a railing .',\n",
       " '604652': 'A group of friends are sleeping against a railing .',\n",
       " '604655': 'a female in a tank top',\n",
       " '604654': 'A female dressed in a gray tank top rides down the sidewalk on her bicycle .',\n",
       " '604657': 'a female rides naked',\n",
       " '604656': 'a female in red tank top',\n",
       " '390490': '5 hostages are sitting inside a building',\n",
       " '622277': 'A woman is sitting in her car drinking a beverage .',\n",
       " '623521': \"A girl rides on her dad 's shoulders .\",\n",
       " '476931': 'Runners 14474 and 12188 run side by side in the New York City Marathon .',\n",
       " '542519': 'Eleven ballerinas pose on stage .',\n",
       " '109851': 'A girl in a school uniform is reading in her town .',\n",
       " '109850': 'The woman likes the colors white and black .',\n",
       " '109853': 'The student is studying for her test tomorrow .',\n",
       " '109852': 'A girl in a uniform is reading .',\n",
       " '109855': 'Three men sit on floor in green room .',\n",
       " '109854': 'A girl is pouring herself a glass of lemonade .',\n",
       " '109857': 'some men are gossiping in a room by sitting in a floor .',\n",
       " '169928': 'A sign is above three employees is black shirts and white aprons .',\n",
       " '109859': 'Three men , one dressed as an Islamic holy man , sit in a room with green walls doing paperwork , .',\n",
       " '109858': 'These are men in indoor',\n",
       " '169925': 'A sign shines above two workers',\n",
       " '169924': 'the men are at church dancing',\n",
       " '169923': \"A sign that displays `` Mongolian BBQ '' shines above two employees in white shirts and caps and green aprons .\",\n",
       " '169922': 'The two restaurant employees are hispanic .',\n",
       " '169921': 'The two employees are exchanging lotto tickets .',\n",
       " '169920': 'The employees are under a sign .',\n",
       " '588312': 'A girl jumps on a trampoline in her backyard outside .',\n",
       " '650146': 'A man pointing into the ear wearing a striped shirt in a small boat filled with many people .',\n",
       " '476930': 'A man goes down a fire pole .',\n",
       " '524502': 'Young woman with headphones makes a large bubble .',\n",
       " '374750': 'Two people are walking by the beach .',\n",
       " '472274': 'A football team plays before a nearly-empty stadium .',\n",
       " '472275': 'A football team plays before a nearly-empty stadium during their spring practice .',\n",
       " '472276': 'A football team plays in a stadium filled to capacity .',\n",
       " '472277': 'A group of football players out on the field during a game along side cheerleaders .',\n",
       " '472270': 'A man dressed as Santa rides in a parade .',\n",
       " '472271': 'santa is in a parade',\n",
       " '472272': 'santa is giving out gifts',\n",
       " '472273': 'A rabbit is in a parade',\n",
       " '562096': \"The man likes the woman 's thighs very much .\",\n",
       " '562097': 'A man and a woman sit together outside .',\n",
       " '562094': 'The man and the woman are sitting together .',\n",
       " '557092': 'The boy in yellow pants dancing for a crowd on the square .',\n",
       " '472278': 'A group of football players and cheerleaders outside',\n",
       " '472279': 'A group of soccer players and cheerleaders',\n",
       " '562090': 'A man is sitting on a wall .',\n",
       " '562091': 'A man and woman are making out',\n",
       " '598198': 'Two people talking to someone running for a position .',\n",
       " '545966': 'Woman are standing under an umbrella',\n",
       " '345899': 'Two guys against a wall , one is in black pants and is upside down , the other man is in khaki rolled up pants holding the other one up .',\n",
       " '345898': 'The men are wearing jerseys .',\n",
       " '345897': 'Two young men are posing with a football .',\n",
       " '345896': 'two men are playing nba live on xbox',\n",
       " '345895': 'two footballers take graduation photos',\n",
       " '345894': 'the men are playing football .',\n",
       " '345893': 'two men are tangled up',\n",
       " '345892': 'Two old guys are posing with a soccer ball .',\n",
       " '345891': 'two men wrestle after a football game',\n",
       " '345890': 'two men with a football pose outside',\n",
       " '183413': 'A girl stands in a driveway .',\n",
       " '183412': 'There are several people in a small boat .',\n",
       " '183411': 'A single person is rowing a canoe on a lake .',\n",
       " '183410': 'A single person rowing a small boat on a lake .',\n",
       " '183417': 'A crowd of people at a festival .',\n",
       " '183416': 'A crowd of scantily clad people at an outdoor festival',\n",
       " '183415': 'A girl is in front of her own house .',\n",
       " '183414': 'A person stands in front of a house .',\n",
       " '374556': 'A woman brushes her dog .',\n",
       " '374557': 'A man spends time with his young son on a boat in the middle of a lake .',\n",
       " '183419': 'A crowd of half naked people at an outdoor festival .',\n",
       " '183418': 'A crowd of clowns at an indoor festival .',\n",
       " '374552': 'The shaver is in a pink shirt .',\n",
       " '374553': 'A man is grooming another man .',\n",
       " '374550': 'A woman sits on a bus with her dog in her lap .',\n",
       " '374551': \"A man in a white shirt shaving another man 's facial hair .\",\n",
       " '390495': 'the kid tries to touch the object',\n",
       " '476936': 'a group is going inside a store',\n",
       " '640257': 'A girl is walking outdoors .',\n",
       " '23266': 'Two women are waiting for a taxi .',\n",
       " '23267': 'Those women are selling local cuisine .',\n",
       " '23264': 'Two women are selling food .',\n",
       " '23265': 'The women are selling t-shirts .',\n",
       " '23262': 'two women sleep on a bed',\n",
       " '23263': 'two women sell food',\n",
       " '23260': 'Two foreign women are selling food that smells bad .',\n",
       " '23261': 'two women sell food they made',\n",
       " '230713': 'A woman and four young boys gather on the porch of a somewhat rundown wooden house .',\n",
       " '230712': 'A couple of guys setting up a bounce house .',\n",
       " '230711': 'A couple of guys setting up a bounce house for a birthday party .',\n",
       " '230710': 'A couple of women setting up a booth at a makeup event .',\n",
       " '132668': 'People wait for an event on the beach to start .',\n",
       " '132669': 'There are humans at in the beach in the daytime .',\n",
       " '23268': 'The women in black are selling a variety of foods .',\n",
       " '23269': 'Two women are sitting against an orange wall behind a few tables covered in food .',\n",
       " '587704': 'The girl needs help climbing the tree .',\n",
       " '476935': 'Crowd on sidewalk waiting to go inside a store .',\n",
       " '374753': 'Someone is practicing .',\n",
       " '483097': 'people are rushing towards the fire extinguisher',\n",
       " '614251': 'Old lady sitting in a room full of flowers .',\n",
       " '510585': 'The cat is grooming itself on the windowsill .',\n",
       " '510584': 'The poodle is happy to be warm .',\n",
       " '553535': 'Two men sit at a diner , one reading a newspaper , the other smoking a cigarette .',\n",
       " '390497': 'the kid backflips off the moon',\n",
       " '641185': 'The people performing are part of a chorus .',\n",
       " '218092': 'A man and a woman sitting down having a conversation .',\n",
       " '218093': 'They are at pizza Hut birthday part as clowns',\n",
       " '218090': 'A young man is talking to Mark Zuccherberg .',\n",
       " '218091': 'The young man is interviewing Mark Zuccherberg for the school newspaper .',\n",
       " '218096': 'The man is floating .',\n",
       " '218097': 'The boardwalk is raised off the beach .',\n",
       " '218094': 'The man and the woman are about to catch the buss at the buss station',\n",
       " '218095': 'A man rides his bike on the boardwalk .',\n",
       " '510581': 'The dog is looking in the sand .',\n",
       " '218098': 'Three workers in bright green vests , taking a break .',\n",
       " '218099': 'workers on break',\n",
       " '542423': 'Boys are playing football .',\n",
       " '510580': 'A dog wearing a green sweater and backpack running in the snow',\n",
       " '510583': 'A dog wearing a green sweater and a backpack walking on snow .',\n",
       " '510582': 'The dog in a green sweater and backpack is searching for something in the snow .',\n",
       " '614253': 'The old lady is making a cake in the kitchen .',\n",
       " '646494': 'two men pose in suits',\n",
       " '557093': 'The boy likes to dance .',\n",
       " '176066': 'A man in shirt talking to another man about the war .',\n",
       " '176067': 'Men discuss something while in front of stand .',\n",
       " '530152': 'There are 4 boys pictured .',\n",
       " '603978': 'Bearded musician is showing his skill .',\n",
       " '325329': 'A bald man smiles at the camera during his cooking show .',\n",
       " '325328': 'A bald man with glasses grins at the camera while he takes the roast poultry out of the oven with his black oven mitts .',\n",
       " '247469': 'The two woman are eating .',\n",
       " '325323': 'Folk went to the theater .',\n",
       " '325322': 'People having a party outdoor .',\n",
       " '325321': 'Folk sit near by fire .',\n",
       " '247468': 'The two woman are brushing their teeth',\n",
       " '325327': 'A group of people are grilling on the porch .',\n",
       " '155687': 'Two young children are shoveling snow off a sidewalk using shovels .',\n",
       " '325325': 'A group of people are around a campfire .',\n",
       " '325324': 'Several people sit by a campfire in the darkness .',\n",
       " '205397': 'The people walk down the trail .',\n",
       " '205396': 'The tourists are walking through a forest trail .',\n",
       " '205395': 'The people walk through the grocery store .',\n",
       " '205394': 'a group of tourists are walking down a paved trail .',\n",
       " '205393': 'The pathway leads to a store .',\n",
       " '205392': 'People are walking outside in the light .',\n",
       " '205391': 'A man sits on the couch .',\n",
       " '247466': 'Two woman , both of which are wearing black shirts , are eating .',\n",
       " '176068': 'Some friends are meeting for lunch',\n",
       " '205399': 'People are in their homes .',\n",
       " '205398': 'People walk down the street on a sunny day .',\n",
       " '640256': 'A girl is walking through the Canadian tundra .',\n",
       " '247464': 'a couple in a car',\n",
       " '651850': 'A snowboarder dressed in yellow snow pants and a helmet catches some air on fresh powder .',\n",
       " '544854': 'A silhouette of a lady looking down with long hair surrounded by yellow , blue , and orange bright lights .',\n",
       " '247463': 'women out for dinner',\n",
       " '206023': 'A man using a barbecue grill .',\n",
       " '247462': 'Two young women in black t-shirts eat food at a table .',\n",
       " '615536': 'A man on a scaffold uses spray paint to work on a mural .',\n",
       " '615537': 'A man uses spray paint .',\n",
       " '615534': 'A man and a woman watch two dogs .',\n",
       " '615535': 'The man and woman are trying to see what the two dogs are doing .',\n",
       " '615532': 'He knows how to ride a bike .',\n",
       " '247461': 'A small group of men sit on the steps .',\n",
       " '615530': 'Animals on a path',\n",
       " '615531': 'A man makes adjustments to a bicycle in the shop .',\n",
       " '84221': 'A girl rolls around in the grass .',\n",
       " '247460': 'Men sit on the church steps waiting on the preacher .',\n",
       " '615538': 'A man is painting a giant mural for a blood bank with spray paint .',\n",
       " '1679': 'A crowded street in Asia .',\n",
       " '506447': 'Two kids with bicycles are at a bmx park getting rained on .',\n",
       " '506446': 'A lady working with her hat on .',\n",
       " '506445': 'A lady eats a mango .',\n",
       " '506444': 'A lady at work .',\n",
       " '506443': 'One lady working at a convenience store .',\n",
       " '363198': 'Two workers are naked',\n",
       " '506441': 'a man cooks lunch at work',\n",
       " '506440': 'She is baking a cake for church .',\n",
       " '155689': 'Two young children shovel snow outside an apartment complex .',\n",
       " '363199': 'Two workers wearing orange vests going over paperwork .',\n",
       " '506449': 'Some children are taking advantage of the good weather and using the bmx park .',\n",
       " '155688': 'Two young children are shoveling snow off a sidewalk , while grandma is making tea inside . .',\n",
       " '363196': 'Two workers are wearing orange vests on top of the telephone pole',\n",
       " '554375': 'The boy is looking up at the sky with a black and white shirt on .',\n",
       " '566249': 'A woman is outside of a grocery store .',\n",
       " '363197': 'Two workers are highly visable',\n",
       " '637873': 'A dog is hunting with its owner .',\n",
       " '363194': 'Two jockeys whip their horses to run faster toward the finish line .',\n",
       " '363195': 'two construction workers wearing orange vests',\n",
       " '542422': 'a group of boys play baseball',\n",
       " '554370': 'A boy stands on top of some monkey bars eating an ice cream cone .',\n",
       " '624083': 'A baseball player is sleeping .',\n",
       " '415760': 'Two people are waiting for their friend to leave the club .',\n",
       " '84229': 'The boy is bathing .',\n",
       " '619956': 'An Olympic athlete performs in the javelin throw event .',\n",
       " '554371': 'A boy is weaing a plad white and brown shirt .',\n",
       " '619950': 'A crowd of people stand outside a building in the dark .',\n",
       " '619951': 'A crowd of people wait outside the DMV at night .',\n",
       " '601858': 'the dog is in the snow',\n",
       " '1671': 'Nobody is on the street in Asia .',\n",
       " '555340': 'she have two backs .',\n",
       " '463001': 'two aldies are wearing neon colors',\n",
       " '555342': \"she do n't have anything\",\n",
       " '555343': 'A child jumping from a slide into a pool .',\n",
       " '555344': 'A child jumping into the water .',\n",
       " '363190': 'Dog is willing to jump on a bush .',\n",
       " '551335': 'a little boy with a ball cap on his head and sunglasses in one hand is writing on a white banner with lots of signatures .',\n",
       " '353266': 'Man in gold bike looks at New York',\n",
       " '555348': 'Two men are wearing blue shirts .',\n",
       " '555349': 'The man and woman are blind .',\n",
       " '462448': 'A black and white dog running from under a yellow cover with a person behind them .',\n",
       " '363191': 'Two jockeys race to the finish line .',\n",
       " '463003': 'A man in a gray suit locking up a bicycle',\n",
       " '651507': 'The woman is in an outdoor park',\n",
       " '135944': 'A desk is surrounded by people walking around .',\n",
       " '135945': 'People are stuck in an elevator .',\n",
       " '135946': 'Men and women surround a desk .',\n",
       " '135947': 'People milling around the information booth .',\n",
       " '135940': 'A man watches a little boy swim without a life jacket .',\n",
       " '135941': 'The father is teaching his son to swim .',\n",
       " '135942': 'A little boy is having fun with his father while swimming in a lake .',\n",
       " '135943': 'People mill about a large are with a round desk .',\n",
       " '463005': 'A person is dressed in gray',\n",
       " '135948': 'A crowd moves about .',\n",
       " '135949': 'Only one person is visible .',\n",
       " '463004': 'A man has just ridden his bike to work .',\n",
       " '170914': 'A human on a bridge and a blue sky .',\n",
       " '170915': 'A human on a short bridge .',\n",
       " '170916': 'A man is on the bridge .',\n",
       " '170917': 'The person is looking down at the water .',\n",
       " '170910': 'Someone one with the nature .',\n",
       " '170911': 'A woman on a long bridge with a clear blue sky .',\n",
       " '170912': 'there is someone outside',\n",
       " '170913': 'Someone attempting for suicide on a bridge .',\n",
       " '353260': 'A man is dressed in biking clothing .',\n",
       " '170918': 'The bridge is over a body of water .',\n",
       " '170919': 'It is a cloudy day .',\n",
       " '38569': 'A man is speaking into a megaphone .',\n",
       " '38568': 'The man is speaking to the crowd',\n",
       " '281078': 'A policeman on the job .',\n",
       " '281079': 'A policeman checking the license of a driver .',\n",
       " '517913': 'A white man is sitting in a chair',\n",
       " '517912': 'An overweight white man is wearing a blue tee-shirt',\n",
       " '517911': 'a man is giving a lecture on pi',\n",
       " '517910': 'a man is searching his online dating page at home',\n",
       " '38561': 'A man speaks his mind',\n",
       " '38560': 'A hard working man speaks his mind into his megaphone .',\n",
       " '38563': \"A man does n't speak his mind\",\n",
       " '38562': 'A man happily speaks his mind',\n",
       " '38565': 'The man is driving his car',\n",
       " '38564': 'A man in a blue shirt is speaking into a megaphone .',\n",
       " '38567': 'A man is addressing a crowd .',\n",
       " '38566': 'A man addresses a school assembly .',\n",
       " '320298': 'a woman rides an atv .',\n",
       " '320299': 'There is a person on a bicycle .',\n",
       " '551337': 'A woman signs a cast .',\n",
       " '628547': 'There are people near a bike',\n",
       " '554349': 'A man is kneeling on a metal roof and is looking over a structure on the roof .',\n",
       " '320290': 'A person rides a bike',\n",
       " '320291': 'A boy rides his new bike',\n",
       " '320292': 'A biker is doing tricks on his bike .',\n",
       " '320293': 'The biker is male',\n",
       " '320294': 'The biker is not just riding his bike in a normal fashion',\n",
       " '320295': 'The person is doing tricks on his skateboard',\n",
       " '320296': 'A man wearing a red helmet rides a bike .',\n",
       " '320297': 'A man is driving a car with nothing on his head .',\n",
       " '236904': 'A man in a Hawaiian shirt and a small boy are playing indoors with a wooden train set .',\n",
       " '236905': 'A man wearing a Hawaiian shirt and a small boy are building a wooden train set',\n",
       " '236906': 'A man wearing a Hawaiian shirt and a small boy are playing with a wooden train set',\n",
       " '236907': 'A man wearing a Hawaiian shirt and a small boy are playing with a steel train set',\n",
       " '236900': 'A woman has a castle behind her as she walks to the top of an escalator .',\n",
       " '236901': 'A woman in a yellow pantsuit heads to the down escalator in a building with large windows .',\n",
       " '236902': 'woman going to work',\n",
       " '236903': 'woman in pantsuit',\n",
       " '622749': 'the head of the indians was dressed for a raindance',\n",
       " '192575': 'The truck is covered',\n",
       " '236908': 'A Man with a fishing pole standing on a beach .',\n",
       " '236909': 'A man is letting the waves hit his feet .',\n",
       " '246204': 'Every person who is shown is wearing only blue clothing .',\n",
       " '246205': 'The woman is talking to her son .',\n",
       " '246206': 'Woman in blue dress talking',\n",
       " '246207': 'A person in red talks on the phone .',\n",
       " '246200': 'A woman talks to her friend on the phone .',\n",
       " '246201': 'This lady is talking to her boyfriend .',\n",
       " '246202': 'The woman is wearing a yellow blazer .',\n",
       " '246203': 'Woman talking on cellphone',\n",
       " '468156': 'Soldiers are gathered together for an awards ceremony .',\n",
       " '246208': 'a woman talks to her kid',\n",
       " '246209': 'Two men are lying on a roof doing work , while two other men are assisting using a lift .',\n",
       " '468157': 'Men in uniform are gathered together in a pub for new years .',\n",
       " '498474': 'A man on a street corner .',\n",
       " '175249': 'People , wearing the same color , are near a subway .',\n",
       " '175248': 'The prisoners are picking up litter .',\n",
       " '548280': 'Two women are bathing at a spa .',\n",
       " '175243': 'The ladies are cleaning the inside of the train .',\n",
       " '175242': 'Men in jumpsuits clean up a subway .',\n",
       " '175241': 'Convicts attempt to flee a train station .',\n",
       " '175240': 'A group of people in blue are vandalizing a subway .',\n",
       " '175247': 'Men are littering in the subway station .',\n",
       " '175246': 'Workers are volunteering to clean up the subway .',\n",
       " '175245': 'Some volunteers help clean up beside a subway .',\n",
       " '175244': 'The men are cleaning .',\n",
       " '637872': \"A dog is tearing at the deers ' throat .\",\n",
       " '123949': 'Two people are not standing .',\n",
       " '123948': 'A mother and daughter are having dinner in the dining room .',\n",
       " '123943': 'The dog is enjoying the outdoors .',\n",
       " '123942': 'The dog is biting someone as they try to run away .',\n",
       " '123941': \"The dog 's owner took the dog for a walk .\",\n",
       " '123940': 'The large brown dog is sitting on the path next to a tree .',\n",
       " '123947': 'A parent and child sitting together .',\n",
       " '123946': \"The dog is wating for it 's owner .\",\n",
       " '123945': 'The dog is asleep om the sofa .',\n",
       " '123944': 'A large dog sits in the grass .',\n",
       " '300872': 'There are people standing near the ledge of the ocean .',\n",
       " '300873': 'The people are holding hands while taking in the view of the ocean .',\n",
       " '300870': 'The men are looking over the cliff .',\n",
       " '300871': 'Two people stand on a cliff overlooking the ocean .',\n",
       " '300876': 'The people are watching a movie in their house .',\n",
       " '300877': 'The people are watching the sun set on the water .',\n",
       " '300874': 'The two people are riding in a car .',\n",
       " '300875': 'Two people at the top of a beach side cliff .',\n",
       " '442451': 'The boy is getting his picture taken while jumping .',\n",
       " '300878': 'There are people on the cliff .',\n",
       " '300879': 'two men stand on a cliff top overlooking a sandy beach .',\n",
       " '137872': 'Two people are walking on a road holding hands',\n",
       " '398738': 'Men taking their lunch break .',\n",
       " '398739': 'Men playing poker at home .',\n",
       " '398734': 'A young girl is smiling at her friend while they play in a field',\n",
       " '398735': 'A smiling young girl is in a field',\n",
       " '398736': 'A young girl is laughing at clowns at the circus',\n",
       " '398737': '5 men in yellow vest working at construction site .',\n",
       " '398730': 'Five men are trying to sled on a grassy knoll .',\n",
       " '398731': 'The five men who are sledding are friends .',\n",
       " '398732': 'Five men in winter clothing are by a hill .',\n",
       " '398733': 'A young girl smiles in a field .',\n",
       " '83637': 'The person knows how to do a flip .',\n",
       " ...}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_test.sentence_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 94, 5586, 6924, 331, 3110, 4207, 6319, 9074, 22],\n",
       " [1, 94, 5586, 6924, 734, 6319, 9754, 3657, 22, 0],\n",
       " 2,\n",
       " ['<sos>',\n",
       "  'a',\n",
       "  'man',\n",
       "  'playing',\n",
       "  'an',\n",
       "  'electric',\n",
       "  'guitar',\n",
       "  'on',\n",
       "  'stage',\n",
       "  '.'],\n",
       " ['<sos>', 'a', 'man', 'playing', 'banjo', 'on', 'the', 'floor', '.', '<pad>'],\n",
       " 9]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_test.test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_baseline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from models import Baseline_Embeddings, Baseline_LSTM\n",
    "from utils import to_gpu, Corpus, batchify, SNLIDataset, collate_snli\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt1",
   "language": "python",
   "name": "pt1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
